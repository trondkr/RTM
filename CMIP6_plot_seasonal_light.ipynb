{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.style.use(\"default\")\n",
    "import os, sys\n",
    "from shapely.geometry import mapping\n",
    "import geopandas as gpd\n",
    "import texttable\n",
    "import global_land_mask\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "sys.path.append(\"../CMIP6-downscale/\")\n",
    "from CMIP6_ridgeplot import CMIP6_ridgeplot\n",
    "from xclim import ensembles\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "from CMIP6_IO import CMIP6_IO\n",
    "\n",
    "import pyproj\n",
    "\n",
    "pyproj.datadir.set_data_dir(\"/home/sam/miniconda3/envs/actea-3.9/share/proj/\")\n",
    "pyproj.datadir.get_data_dir()\n",
    "plt.style.use(\"default\")\n",
    "sns.set(font_scale=1.1, style=\"whitegrid\")\n",
    "io = CMIP6_IO()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Plot PAR as either monthly distributions per time periods (e.g. 1993-2010), or plot heatmaps showing the difference in PAR for an area per month and how the values change into the future.\n",
    "\n",
    "FRA to SFO 26.10.2022, modified 20.04.2023\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def get_LME_records():\n",
    "    lme_file = \"gs://actea-shared/Shapefiles/LME66/LMEs66.shp\"\n",
    "    return gpd.read_file(lme_file)\n",
    "\n",
    "\n",
    "def get_LME_records_180():\n",
    "    lme_file = \"gs://actea-shared/Shapefiles/LME66_180/LME66_180.shp\"\n",
    "    return gpd.read_file(lme_file)\n",
    "\n",
    "\n",
    "def create_colors(N):\n",
    "    color = iter(cm.tab20b(np.linspace(0, 1, N)))\n",
    "    return [next(color) for c in range(N)]\n",
    "\n",
    "\n",
    "def get_data_within_LME(ds, LME):\n",
    "    # Extract the polygon defining the boundaries of the LME\n",
    "    # if LME==\"Barents Sea\":\n",
    "    shdf = get_LME_records()\n",
    "    # elif LME==\"Northern Bering - Chukchi Seas\":\n",
    "    #    shdf = get_LME_records_180()\n",
    "    # else:\n",
    "    #    raise ValueError(\"LME not found\")\n",
    "\n",
    "    shdf_sel = shdf[shdf[\"LME_NAME\"] == LME]\n",
    "    clipped = None\n",
    "\n",
    "    ds = ds.rio.write_crs(\"epsg:4326\", inplace=True)\n",
    "    ds = ds.rio.set_spatial_dims(x_dim=\"lon\", y_dim=\"lat\", inplace=True)\n",
    "\n",
    "    clipped = ds.rio.clip(geometries=shdf_sel.geometry.apply(mapping), crs=ds.rio.crs)\n",
    "    area_calc = shdf_sel[\"geometry\"].to_crs({\"proj\": \"cea\"})\n",
    "\n",
    "    print(f\"Total area of LME {LME} in km2 {area_calc.area / 10**6}\")\n",
    "    # Rioxarray requires x and y dimensions - we convert these back to lon and lat later.\n",
    "    # We also add the projection (lat-lon) so that rioxarray can do the clipping of the data according to the\n",
    "    # shapefile.\n",
    "\n",
    "    return clipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def convert_to_180(ds):\n",
    "    if len(ds.lon.dims) == 2:\n",
    "        ds = (ds.assign_coords(x=(((ds.x + 180) % 360) - 180))).sortby(\"x\")\n",
    "\n",
    "        ds = ds.assign_coords(y=ds.lat[:, 0].values, x=ds.x)\n",
    "        ds = ds.drop([\"lat\", \"lon\"])\n",
    "        ds = ds.rename({\"y\": \"lat\", \"x\": \"lon\"})\n",
    "    else:\n",
    "        ds = (ds.assign_coords(lon=(((ds.lon + 180) % 360) - 180))).sortby(\"lon\")\n",
    "    return ds\n",
    "\n",
    "\n",
    "def convert_time(ds):\n",
    "    if not ds.indexes[\"time\"].dtype in [\"datetime64[ns]\"]:\n",
    "        time_objects = ds.indexes[\"time\"].to_datetimeindex()\n",
    "        ds = ds.assign_coords({\"time\": time_objects})\n",
    "        ds = xr.decode_cf(ds)\n",
    "\n",
    "    return ds\n",
    "\n",
    "\n",
    "def create_land_ocean_mask(cmip6_grid: xr.Dataset) -> xr.DataArray:\n",
    "    print(\"[create_land_ocean_mask] Running create_land_ocean_mask\")\n",
    "    lon = cmip6_grid.lon.values\n",
    "    lat = cmip6_grid.lat.values\n",
    "    lon_180 = xr.where(lon > 180, lon - 360, lon)\n",
    "    lon_grid, lat_grid = np.meshgrid(lon_180, lat)\n",
    "    mask_data = global_land_mask.globe.is_ocean(lat_grid, lon_grid).astype(int)\n",
    "\n",
    "    return xr.DataArray(mask_data, coords={\"lat\": lat, \"lon\": lon}, dims=[\"lat\", \"lon\"])\n",
    "\n",
    "\n",
    "def get_area_averaged_ds(\n",
    "    ds, model, scenario, ensemble_id, var_name, LME, models_dict, start_time, end_time\n",
    "):\n",
    "    if isinstance(ds, xr.Dataset):\n",
    "        print(ds)\n",
    "        ds = convert_to_180(ds)\n",
    "        print(ds)\n",
    "        ds = ds.sel(time=slice(start_time, end_time))\n",
    "        ds = convert_time(ds)\n",
    "\n",
    "        # Convert from kg/m-3 to mg/m-3\n",
    "        if var_name == \"chl\":\n",
    "            ds[f\"{var_name}_mean\"] = ds[f\"{var_name}_mean\"] * 1.0e6\n",
    "\n",
    "        ds_lme = get_data_within_LME(ds, LME)\n",
    "        ds_lme[\"mask\"] = create_land_ocean_mask(ds_lme.isel(time=0))\n",
    "        ds_lme = ds_lme.where(ds_lme.mask == 1)\n",
    "\n",
    "        model_info = {}\n",
    "        model_info[\"model_name\"] = model\n",
    "        model_info[\"model_scenario\"] = scenario\n",
    "        model_info[\"model_ensemble_id\"] = ensemble_id\n",
    "        model_info[\"model_var\"] = var_name\n",
    "        model_info[\"LME\"] = LME\n",
    "        key = \"{}_{}_{}_{}\".format(model, ensemble_id, scenario, var_name)\n",
    "        models_dict[key] = model_info\n",
    "        return models_dict, ds_lme\n",
    "    else:\n",
    "        return models_dict, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def create_summary_table(dict_of_models, LME):\n",
    "    table = texttable.Texttable()\n",
    "    table.set_cols_align([\"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\"])\n",
    "    table.set_cols_valign([\"t\", \"t\", \"m\", \"m\", \"m\", \"m\", \"b\"])\n",
    "\n",
    "    table.header([\"LME\", \"Model\", \"Scenario\", \"ID\", \"Var\", \"CMIP6 min\", \"CMIP6 max\"])\n",
    "    for key in dict_of_models.keys():\n",
    "        model = dict_of_models[key]\n",
    "\n",
    "        table.add_row(\n",
    "            [\n",
    "                LME,\n",
    "                model[\"model_name\"],\n",
    "                model[\"model_scenario\"],\n",
    "                model[\"model_ensemble_id\"],\n",
    "                str(model[\"model_var\"]),\n",
    "                str(model[\"model_var\"]),\n",
    "                str(model[\"model_var\"]),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    table.set_cols_width([30, 30, 20, 20, 10, 10, 10])\n",
    "    print(table.draw() + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "light/ncfiles/ensemble/par_ensemble_stats_ssp245.nc\n",
      "[CMIP6_IO] Opening file actea-shared/light/ncfiles/ensemble/par_ensemble_stats_ssp245.nc\n",
      "DatasetWeighted with weights along dimensions: lat\n",
      "None\n",
      "light/ncfiles/ensemble/par_ensemble_stats_ssp585.nc\n",
      "[CMIP6_IO] Opening file actea-shared/light/ncfiles/ensemble/par_ensemble_stats_ssp585.nc\n",
      "DatasetWeighted with weights along dimensions: lat\n",
      "None\n",
      "light/ncfiles/ensemble/par_ensemble_stats_ssp245.nc\n",
      "[CMIP6_IO] Opening file actea-shared/light/ncfiles/ensemble/par_ensemble_stats_ssp245.nc\n",
      "DatasetWeighted with weights along dimensions: lat\n",
      "None\n",
      "light/ncfiles/ensemble/par_ensemble_stats_ssp585.nc\n",
      "[CMIP6_IO] Opening file actea-shared/light/ncfiles/ensemble/par_ensemble_stats_ssp585.nc\n",
      "DatasetWeighted with weights along dimensions: lat\n",
      "None\n",
      "light/ncfiles/ensemble/uv_ensemble_stats_ssp245.nc\n",
      "[CMIP6_IO] Opening file actea-shared/light/ncfiles/ensemble/uv_ensemble_stats_ssp245.nc\n",
      "DatasetWeighted with weights along dimensions: lat\n",
      "None\n",
      "light/ncfiles/ensemble/uv_ensemble_stats_ssp585.nc\n",
      "[CMIP6_IO] Opening file actea-shared/light/ncfiles/ensemble/uv_ensemble_stats_ssp585.nc\n",
      "DatasetWeighted with weights along dimensions: lat\n",
      "None\n",
      "light/ncfiles/ensemble/uv_ensemble_stats_ssp245.nc\n",
      "[CMIP6_IO] Opening file actea-shared/light/ncfiles/ensemble/uv_ensemble_stats_ssp245.nc\n",
      "DatasetWeighted with weights along dimensions: lat\n",
      "None\n",
      "light/ncfiles/ensemble/uv_ensemble_stats_ssp585.nc\n",
      "[CMIP6_IO] Opening file actea-shared/light/ncfiles/ensemble/uv_ensemble_stats_ssp585.nc\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/xarray/backends/file_manager.py:201\u001b[0m, in \u001b[0;36mCachingFileManager._acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 201\u001b[0m     file \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cache[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_key]\n\u001b[1;32m    202\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/xarray/backends/lru_cache.py:55\u001b[0m, in \u001b[0;36mLRUCache.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m---> 55\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cache[key]\n\u001b[1;32m     56\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cache\u001b[39m.\u001b[39mmove_to_end(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: [<class 'h5netcdf.core.File'>, (<File-like object GCSFileSystem, actea-shared/light/ncfiles/ensemble/uv_ensemble_stats_ssp585.nc>,), 'r', (('decode_vlen_strings', True), ('invalid_netcdf', None))]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/tk/cmip6-albedo/CMIP6_plot_seasonal_light.ipynb Cell 6\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bactea-dev-vm/home/tk/cmip6-albedo/CMIP6_plot_seasonal_light.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m     fname \u001b[39m=\u001b[39m (\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bactea-dev-vm/home/tk/cmip6-albedo/CMIP6_plot_seasonal_light.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlight/ncfiles/ensemble/\u001b[39m\u001b[39m{\u001b[39;00mvar_name\u001b[39m}\u001b[39;00m\u001b[39m_ensemble_stats_\u001b[39m\u001b[39m{\u001b[39;00mscenario\u001b[39m}\u001b[39;00m\u001b[39m.nc\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bactea-dev-vm/home/tk/cmip6-albedo/CMIP6_plot_seasonal_light.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bactea-dev-vm/home/tk/cmip6-albedo/CMIP6_plot_seasonal_light.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39mprint\u001b[39m(fname)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bactea-dev-vm/home/tk/cmip6-albedo/CMIP6_plot_seasonal_light.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m ds_unweighted \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39;49mopen_dataset_on_gs(fname)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bactea-dev-vm/home/tk/cmip6-albedo/CMIP6_plot_seasonal_light.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39m# Calculate the area-weighted average\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bactea-dev-vm/home/tk/cmip6-albedo/CMIP6_plot_seasonal_light.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=35'>36</a>\u001b[0m weights \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mcos(np\u001b[39m.\u001b[39mdeg2rad(ds_unweighted\u001b[39m.\u001b[39mlat))\n",
      "File \u001b[0;32m~/cmip6-albedo/CMIP6_IO.py:113\u001b[0m, in \u001b[0;36mCMIP6_IO.open_dataset_on_gs\u001b[0;34m(self, file_name, decode_times)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[CMIP6_IO] Opening file \u001b[39m\u001b[39m{\u001b[39;00mfile_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    112\u001b[0m fileObj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfs\u001b[39m.\u001b[39mopen(file_name)\n\u001b[0;32m--> 113\u001b[0m \u001b[39mreturn\u001b[39;00m xr\u001b[39m.\u001b[39;49mopen_dataset(fileObj, engine\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mh5netcdf\u001b[39;49m\u001b[39m\"\u001b[39;49m, decode_times\u001b[39m=\u001b[39;49mdecode_times)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/xarray/backends/api.py:531\u001b[0m, in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, inline_array, backend_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    519\u001b[0m decoders \u001b[39m=\u001b[39m _resolve_decoders_kwargs(\n\u001b[1;32m    520\u001b[0m     decode_cf,\n\u001b[1;32m    521\u001b[0m     open_backend_dataset_parameters\u001b[39m=\u001b[39mbackend\u001b[39m.\u001b[39mopen_dataset_parameters,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    527\u001b[0m     decode_coords\u001b[39m=\u001b[39mdecode_coords,\n\u001b[1;32m    528\u001b[0m )\n\u001b[1;32m    530\u001b[0m overwrite_encoded_chunks \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39moverwrite_encoded_chunks\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m--> 531\u001b[0m backend_ds \u001b[39m=\u001b[39m backend\u001b[39m.\u001b[39;49mopen_dataset(\n\u001b[1;32m    532\u001b[0m     filename_or_obj,\n\u001b[1;32m    533\u001b[0m     drop_variables\u001b[39m=\u001b[39;49mdrop_variables,\n\u001b[1;32m    534\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mdecoders,\n\u001b[1;32m    535\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    536\u001b[0m )\n\u001b[1;32m    537\u001b[0m ds \u001b[39m=\u001b[39m _dataset_from_backend_dataset(\n\u001b[1;32m    538\u001b[0m     backend_ds,\n\u001b[1;32m    539\u001b[0m     filename_or_obj,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    548\u001b[0m )\n\u001b[1;32m    549\u001b[0m \u001b[39mreturn\u001b[39;00m ds\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/xarray/backends/h5netcdf_.py:389\u001b[0m, in \u001b[0;36mH5netcdfBackendEntrypoint.open_dataset\u001b[0;34m(self, filename_or_obj, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, use_cftime, decode_timedelta, format, group, lock, invalid_netcdf, phony_dims, decode_vlen_strings)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mopen_dataset\u001b[39m(\n\u001b[1;32m    370\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    371\u001b[0m     filename_or_obj,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    385\u001b[0m     decode_vlen_strings\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    386\u001b[0m ):\n\u001b[1;32m    388\u001b[0m     filename_or_obj \u001b[39m=\u001b[39m _normalize_path(filename_or_obj)\n\u001b[0;32m--> 389\u001b[0m     store \u001b[39m=\u001b[39m H5NetCDFStore\u001b[39m.\u001b[39;49mopen(\n\u001b[1;32m    390\u001b[0m         filename_or_obj,\n\u001b[1;32m    391\u001b[0m         \u001b[39mformat\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mformat\u001b[39;49m,\n\u001b[1;32m    392\u001b[0m         group\u001b[39m=\u001b[39;49mgroup,\n\u001b[1;32m    393\u001b[0m         lock\u001b[39m=\u001b[39;49mlock,\n\u001b[1;32m    394\u001b[0m         invalid_netcdf\u001b[39m=\u001b[39;49minvalid_netcdf,\n\u001b[1;32m    395\u001b[0m         phony_dims\u001b[39m=\u001b[39;49mphony_dims,\n\u001b[1;32m    396\u001b[0m         decode_vlen_strings\u001b[39m=\u001b[39;49mdecode_vlen_strings,\n\u001b[1;32m    397\u001b[0m     )\n\u001b[1;32m    399\u001b[0m     store_entrypoint \u001b[39m=\u001b[39m StoreBackendEntrypoint()\n\u001b[1;32m    401\u001b[0m     ds \u001b[39m=\u001b[39m store_entrypoint\u001b[39m.\u001b[39mopen_dataset(\n\u001b[1;32m    402\u001b[0m         store,\n\u001b[1;32m    403\u001b[0m         mask_and_scale\u001b[39m=\u001b[39mmask_and_scale,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    409\u001b[0m         decode_timedelta\u001b[39m=\u001b[39mdecode_timedelta,\n\u001b[1;32m    410\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/xarray/backends/h5netcdf_.py:181\u001b[0m, in \u001b[0;36mH5NetCDFStore.open\u001b[0;34m(cls, filename, mode, format, group, lock, autoclose, invalid_netcdf, phony_dims, decode_vlen_strings)\u001b[0m\n\u001b[1;32m    178\u001b[0m         lock \u001b[39m=\u001b[39m combine_locks([HDF5_LOCK, get_write_lock(filename)])\n\u001b[1;32m    180\u001b[0m manager \u001b[39m=\u001b[39m CachingFileManager(h5netcdf\u001b[39m.\u001b[39mFile, filename, mode\u001b[39m=\u001b[39mmode, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m--> 181\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m(manager, group\u001b[39m=\u001b[39;49mgroup, mode\u001b[39m=\u001b[39;49mmode, lock\u001b[39m=\u001b[39;49mlock, autoclose\u001b[39m=\u001b[39;49mautoclose)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/xarray/backends/h5netcdf_.py:132\u001b[0m, in \u001b[0;36mH5NetCDFStore.__init__\u001b[0;34m(self, manager, group, mode, lock, autoclose)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mformat \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[39m# todo: utilizing find_root_and_group seems a bit clunky\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[39m#  making filename available on h5netcdf.Group seems better\u001b[39;00m\n\u001b[0;32m--> 132\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_filename \u001b[39m=\u001b[39m find_root_and_group(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mds)[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mfilename\n\u001b[1;32m    133\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_remote \u001b[39m=\u001b[39m is_remote_uri(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_filename)\n\u001b[1;32m    134\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlock \u001b[39m=\u001b[39m ensure_lock(lock)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/xarray/backends/h5netcdf_.py:192\u001b[0m, in \u001b[0;36mH5NetCDFStore.ds\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m    191\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mds\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 192\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_acquire()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/xarray/backends/h5netcdf_.py:184\u001b[0m, in \u001b[0;36mH5NetCDFStore._acquire\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_acquire\u001b[39m(\u001b[39mself\u001b[39m, needs_lock\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m--> 184\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_manager\u001b[39m.\u001b[39macquire_context(needs_lock) \u001b[39mas\u001b[39;00m root:\n\u001b[1;32m    185\u001b[0m         ds \u001b[39m=\u001b[39m _nc4_require_group(\n\u001b[1;32m    186\u001b[0m             root, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_group, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mode, create_group\u001b[39m=\u001b[39m_h5netcdf_create_group\n\u001b[1;32m    187\u001b[0m         )\n\u001b[1;32m    188\u001b[0m     \u001b[39mreturn\u001b[39;00m ds\n",
      "File \u001b[0;32m/home/sam/miniconda3/envs/actea-3.9/lib/python3.9/contextlib.py:119\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwds, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc\n\u001b[1;32m    118\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 119\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgen)\n\u001b[1;32m    120\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m    121\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mgenerator didn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt yield\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/xarray/backends/file_manager.py:189\u001b[0m, in \u001b[0;36mCachingFileManager.acquire_context\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[39m@contextlib\u001b[39m\u001b[39m.\u001b[39mcontextmanager\n\u001b[1;32m    187\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39macquire_context\u001b[39m(\u001b[39mself\u001b[39m, needs_lock\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    188\u001b[0m     \u001b[39m\"\"\"Context manager for acquiring a file.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 189\u001b[0m     file, cached \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_acquire_with_cache_info(needs_lock)\n\u001b[1;32m    190\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    191\u001b[0m         \u001b[39myield\u001b[39;00m file\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/xarray/backends/file_manager.py:207\u001b[0m, in \u001b[0;36mCachingFileManager._acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    205\u001b[0m     kwargs \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m    206\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mmode\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mode\n\u001b[0;32m--> 207\u001b[0m file \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_opener(\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    208\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    209\u001b[0m     \u001b[39m# ensure file doesn't get overridden when opened again\u001b[39;00m\n\u001b[1;32m    210\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39ma\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/h5netcdf/core.py:1028\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, path, mode, invalid_netcdf, phony_dims, **kwargs)\u001b[0m\n\u001b[1;32m   1026\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_max_dim_id \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m   1027\u001b[0m \u001b[39m# This maps keeps track of all HDF5 datasets corresponding to this group.\u001b[39;00m\n\u001b[0;32m-> 1028\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_all_h5groups \u001b[39m=\u001b[39m ChainMap(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_h5group)\n\u001b[1;32m   1029\u001b[0m \u001b[39msuper\u001b[39m(File, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_h5path)\n\u001b[1;32m   1030\u001b[0m \u001b[39m# get maximum dimension id and count of labeled dimensions\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/h5netcdf/core.py:505\u001b[0m, in \u001b[0;36mGroup._h5group\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m    502\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_h5group\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    503\u001b[0m     \u001b[39m# Always refer to the root file and store not h5py object\u001b[39;00m\n\u001b[1;32m    504\u001b[0m     \u001b[39m# subclasses:\u001b[39;00m\n\u001b[0;32m--> 505\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_root\u001b[39m.\u001b[39;49m_h5file[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_h5path]\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/home/sam/miniconda3/envs/actea-3.9/lib/python3.9/site-packages/h5py/_hl/group.py:305\u001b[0m, in \u001b[0;36mGroup.__getitem__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mInvalid HDF5 object reference\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    304\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(name, (\u001b[39mbytes\u001b[39m, \u001b[39mstr\u001b[39m)):\n\u001b[0;32m--> 305\u001b[0m     oid \u001b[39m=\u001b[39m h5o\u001b[39m.\u001b[39;49mopen(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mid, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_e(name), lapl\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_lapl)\n\u001b[1;32m    306\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    307\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAccessing a group is done with bytes or str, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39m not \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mtype\u001b[39m(name)))\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5o.pyx:190\u001b[0m, in \u001b[0;36mh5py.h5o.open\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5fd.pyx:162\u001b[0m, in \u001b[0;36mh5py.h5fd.H5FD_fileobj_read\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/fsspec/spec.py:1547\u001b[0m, in \u001b[0;36mAbstractBufferedFile.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m   1542\u001b[0m \u001b[39m\"\"\"mirrors builtin file's readinto method\u001b[39;00m\n\u001b[1;32m   1543\u001b[0m \n\u001b[1;32m   1544\u001b[0m \u001b[39mhttps://docs.python.org/3/library/io.html#io.RawIOBase.readinto\u001b[39;00m\n\u001b[1;32m   1545\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1546\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mmemoryview\u001b[39m(b)\u001b[39m.\u001b[39mcast(\u001b[39m\"\u001b[39m\u001b[39mB\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1547\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(out\u001b[39m.\u001b[39;49mnbytes)\n\u001b[1;32m   1548\u001b[0m out[: \u001b[39mlen\u001b[39m(data)] \u001b[39m=\u001b[39m data\n\u001b[1;32m   1549\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlen\u001b[39m(data)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/fsspec/spec.py:1537\u001b[0m, in \u001b[0;36mAbstractBufferedFile.read\u001b[0;34m(self, length)\u001b[0m\n\u001b[1;32m   1534\u001b[0m \u001b[39mif\u001b[39;00m length \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1535\u001b[0m     \u001b[39m# don't even bother calling fetch\u001b[39;00m\n\u001b[1;32m   1536\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1537\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcache\u001b[39m.\u001b[39;49m_fetch(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloc, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloc \u001b[39m+\u001b[39;49m length)\n\u001b[1;32m   1538\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloc \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(out)\n\u001b[1;32m   1539\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/fsspec/caching.py:154\u001b[0m, in \u001b[0;36mReadAheadCache._fetch\u001b[0;34m(self, start, end)\u001b[0m\n\u001b[1;32m    152\u001b[0m     part \u001b[39m=\u001b[39m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    153\u001b[0m end \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msize, end \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocksize)\n\u001b[0;32m--> 154\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfetcher(start, end)  \u001b[39m# new block replaces old\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstart \u001b[39m=\u001b[39m start\n\u001b[1;32m    156\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mend \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstart \u001b[39m+\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache)\n",
      "File \u001b[0;32m/home/sam/miniconda3/envs/actea-3.9/lib/python3.9/site-packages/gcsfs/core.py:1440\u001b[0m, in \u001b[0;36mGCSFile._fetch_range\u001b[0;34m(self, start, end)\u001b[0m\n\u001b[1;32m   1434\u001b[0m \u001b[39m\"\"\"Get data from GCS\u001b[39;00m\n\u001b[1;32m   1435\u001b[0m \n\u001b[1;32m   1436\u001b[0m \u001b[39mstart, end : None or integers\u001b[39;00m\n\u001b[1;32m   1437\u001b[0m \u001b[39m    if not both None, fetch only given range\u001b[39;00m\n\u001b[1;32m   1438\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1439\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1440\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgcsfs\u001b[39m.\u001b[39;49mcat_file(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpath, start\u001b[39m=\u001b[39;49mstart, end\u001b[39m=\u001b[39;49mend)\n\u001b[1;32m   1441\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1442\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnot satisfiable\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mstr\u001b[39m(e):\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/fsspec/asyn.py:91\u001b[0m, in \u001b[0;36msync_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     89\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     90\u001b[0m     \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m obj \u001b[39mor\u001b[39;00m args[\u001b[39m0\u001b[39m]\n\u001b[0;32m---> 91\u001b[0m     \u001b[39mreturn\u001b[39;00m sync(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloop, func, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/fsspec/asyn.py:59\u001b[0m, in \u001b[0;36msync\u001b[0;34m(loop, func, timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m asyncio\u001b[39m.\u001b[39mrun_coroutine_threadsafe(_runner(event, coro, result, timeout), loop)\n\u001b[1;32m     57\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     58\u001b[0m     \u001b[39m# this loops allows thread to get interrupted\u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mif\u001b[39;00m event\u001b[39m.\u001b[39;49mwait(\u001b[39m1\u001b[39;49m):\n\u001b[1;32m     60\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m     61\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/home/sam/miniconda3/envs/actea-3.9/lib/python3.9/threading.py:574\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    572\u001b[0m signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flag\n\u001b[1;32m    573\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 574\u001b[0m     signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    575\u001b[0m \u001b[39mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/home/sam/miniconda3/envs/actea-3.9/lib/python3.9/threading.py:316\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    315\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 316\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39;49macquire(\u001b[39mTrue\u001b[39;49;00m, timeout)\n\u001b[1;32m    317\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    318\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39macquire(\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "scenarios = [\"ssp245\", \"ssp585\"]  # , \"ssp585\"]\n",
    "period = \"1979-01-01-2099-12-16\"\n",
    "start_time = \"1979-01-01\"\n",
    "end_time = \"2099-12-16\"\n",
    "\n",
    "\n",
    "# This script is created only to plot the seasonal mismatch in the\n",
    "# future of chlorophyll.\n",
    "# [\"tas\",\"par\",\"uv\",\"uva\",\"uvb\",\"uvi\",\"chl\"]\n",
    "ds_var_names = [\n",
    "    \"par\",\n",
    "    \"uv\",\n",
    "    \"uva\",\n",
    "    \"uvb\",\n",
    "    \"uvi\",\n",
    "    \"clt\",\n",
    "    \"siconc\",\n",
    "    \"sisnthick\",\n",
    "    \"sithick\",\n",
    "    \"chl\",\n",
    "    \"tos\",\n",
    "    \"tas\",\n",
    "]\n",
    "# ds_var_names = [\"siconc\"] #,\"uva\",\"clt\",\"siconc\",\"sisnthick\",\"sithick\"]\n",
    "\n",
    "seasonal = False\n",
    "cumulative = False\n",
    "LMES = [\"Barents Sea\", \"Northern Bering - Chukchi Seas\"]\n",
    "# LMES = ['Northern Bering - Chukchi Seas']\n",
    "\n",
    "for var_name in ds_var_names:\n",
    "    for LME in LMES:\n",
    "        models_dict = {}\n",
    "        # We loop over all scenarios, ensemble_ids, and models to create a\n",
    "        # list of dataframes that we eventually concatenate together and plot\n",
    "        for scenario in scenarios:\n",
    "            ds_list = []\n",
    "            if var_name in [\n",
    "                \"tos\",\n",
    "                \"chl\",\n",
    "                \"tas\",\n",
    "                \"clt\",\n",
    "                \"siconc\",\n",
    "                \"sisnthick\",\n",
    "                \"sithick\",\n",
    "            ]:\n",
    "                fname = f\"light/{scenario}/ensemble/CMIP6_ensemble__{scenario}_{var_name}.nc\"\n",
    "            else:\n",
    "                fname = (\n",
    "                    f\"light/ncfiles/ensemble/{var_name}_ensemble_stats_{scenario}.nc\"\n",
    "                )\n",
    "\n",
    "            ds = io.open_dataset_on_gs(fname)\n",
    "\n",
    "            models_dict, ens_stats = get_area_averaged_ds(\n",
    "                ds,\n",
    "                \"ensemble\",\n",
    "                scenario,\n",
    "                \"ensemble\",\n",
    "                var_name,\n",
    "                LME,\n",
    "                models_dict,\n",
    "                start_time,\n",
    "                end_time,\n",
    "            )\n",
    "            outfile = f\"Figures/{var_name}_ensemble_{scenario}_{LME}.png\"\n",
    "            print(ens_stats)\n",
    "            if ens_stats is not None:\n",
    "                fig = plt.figure()\n",
    "                # Create timeseries plots\n",
    "                var_name_ens = f\"{var_name}_mean\"\n",
    "                if LME in [\"Barents Sea\"]:\n",
    "                    ax = plt.figure(figsize=(16, 10)).gca(\n",
    "                        projection=ccrs.PlateCarree(central_longitude=0)\n",
    "                    )\n",
    "                else:\n",
    "                    ax = plt.figure(figsize=(16, 10)).gca(\n",
    "                        projection=ccrs.PlateCarree(central_longitude=0)\n",
    "                    )\n",
    "                ens_stats[var_name_ens].isel(time=0).plot(ax=ax)\n",
    "                ax.coastlines()\n",
    "\n",
    "                plt.show()\n",
    "                sns.lineplot(\n",
    "                    x=ens_stats.time.resample(time=\"A\").mean(),\n",
    "                    y=var_name_ens,\n",
    "                    data=ens_stats.mean({\"lat\", \"lon\"}).resample(time=\"A\").mean(),\n",
    "                    label=f\"{var_name}\",\n",
    "                )\n",
    "\n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "                plt.clf()\n",
    "                # Create heatmaps\n",
    "                df = ens_stats.to_dataframe().reset_index()\n",
    "                start_times = [datetime(1980, 1, 1)]\n",
    "                end_times = [datetime(2000, 1, 1)]\n",
    "\n",
    "                step = 10\n",
    "                # TODO: Add longer historical period by joining two lists.\n",
    "                start_times.extend(\n",
    "                    [datetime(2000 + i, 1, 1) for i in range(0, 80, step)]\n",
    "                )\n",
    "                end_times.extend(\n",
    "                    [datetime(2000 + step + i, 1, 1) for i in range(0, 80, step)]\n",
    "                )\n",
    "\n",
    "                labels = []\n",
    "                dfs = []\n",
    "\n",
    "                max_df_dict = {}\n",
    "                if seasonal:\n",
    "                    frequency = \"season\"\n",
    "                else:\n",
    "                    frequency = \"month\"\n",
    "\n",
    "                for start, end in zip(start_times, end_times):\n",
    "                    label = f\"{start.year}-{end.year}\"\n",
    "                    labels.append(label)\n",
    "\n",
    "                    df = CMIP6_ridgeplot.return_df_climatology(\n",
    "                        var_name_ens,\n",
    "                        None,\n",
    "                        start_time=start,\n",
    "                        end_time=end,\n",
    "                        depth_threshold=None,\n",
    "                        ds=ens_stats,\n",
    "                        cumulative=cumulative,\n",
    "                        seasonal=seasonal,\n",
    "                    ).reset_index(level=frequency)\n",
    "\n",
    "                    df.set_index(\"month\", inplace=True)\n",
    "                    dfs.append(df)\n",
    "                    max_df_dict[label] = df[var_name_ens].groupby(\"month\").mean()\n",
    "\n",
    "                fig = plt.figure()\n",
    "                CMIP6_ridgeplot.heatmap_of_change(\n",
    "                    max_df_dict, var_name_ens, labels, 12, LME, scenario\n",
    "                )\n",
    "                # plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
