{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.style.use(\"default\")\n",
    "from pathlib import Path\n",
    "import cftime\n",
    "import os, sys\n",
    "import seaborn as sns\n",
    "import cartopy\n",
    "import cartopy.feature as cpf\n",
    "from global_land_mask import globe\n",
    "import CMIP6_light_map\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from shapely.geometry import box, mapping\n",
    "import geopandas as gpd\n",
    "import rioxarray\n",
    "from matplotlib import cm\n",
    "import cartopy.feature as cpf\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n",
    "import texttable\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "sys.path.append(\"../CMIP6_downscale/\")\n",
    "from CMIP6_ridgeplot import CMIP6_ridgeplot\n",
    "from xclim import ensembles\n",
    "from CMIP6_IO import CMIP6_IO\n",
    "from CMIP6_config import Config_albedo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def convert_to_180(ds):\n",
    "    ds = ds.assign_coords(lat=ds.y)\n",
    "    return (ds.assign_coords(lon=(((ds.x + 180) % 360) - 180))).sortby(\"lon\")\n",
    "\n",
    "\n",
    "def convert_time(ds):\n",
    "    if not ds.indexes[\"time\"].dtype in [\"datetime64[ns]\"]:\n",
    "        time_objects = ds.indexes[\"time\"].to_datetimeindex()\n",
    "        ds = ds.assign_coords({\"time\": time_objects})\n",
    "        ds = xr.decode_cf(ds)\n",
    "\n",
    "    return ds\n",
    "\n",
    "\n",
    "def get_area_averaged_ds(\n",
    "    fname,\n",
    "    model,\n",
    "    scenario,\n",
    "    ensemble_id,\n",
    "    var_name,\n",
    "    LME,\n",
    "    create_maps,\n",
    "    frequency,\n",
    "    models_dict,\n",
    "    fname2=None,\n",
    "):\n",
    "    if os.path.exists(fname):\n",
    "        if var_name not in [\"velocity\"]:\n",
    "            with xr.open_dataset(fname) as ds:\n",
    "                ds = convert_to_180(ds)\n",
    "\n",
    "                ds = ds.sel(\n",
    "                    time=slice(start_time, end_time)\n",
    "                )  # .sel(lat=slice(min_lat,max_lat), lon=slice(min_lon,max_lon))\n",
    "                ds = convert_time(ds)\n",
    "                if var_name in [\"tas\"]:\n",
    "                    ds = xr.where(ds > 100, ds - 273.15, ds)\n",
    "\n",
    "                # Convert from kg/m-3 to mg/m-3\n",
    "                if var_name in [\"chl\"]:\n",
    "                    ds[var_name] = ds[var_name] / 1.0e6\n",
    "\n",
    "                ds_lme = get_data_within_LME(ds, var_name, LME, create_maps)\n",
    "\n",
    "                outfile = \"Figures/{}_ensemble_{}_{}_ridgeplot.png\".format(\n",
    "                    var_name.capitalize(), scenario, LME\n",
    "                )\n",
    "                print(f\"Creating ridgeplot: {outfile}\")\n",
    "\n",
    "                #  CMIP6_ridgeplot.ridgeplot(var_name,\n",
    "                #                            None, outfile,\n",
    "                #                            glorys=False, depth_threshold=None,\n",
    "                #                            ds=ds_lme)\n",
    "\n",
    "                ds = ds_lme.mean({\"lat\", \"lon\"})\n",
    "                ds = ds.assign(TOZ_std=ds_lme[var_name].std({\"lat\", \"lon\"}))\n",
    "                df = ds.to_dataframe().dropna()\n",
    "\n",
    "                df = df.reset_index()\n",
    "\n",
    "        else:\n",
    "            with xr.open_mfdataset([fname, fname2]) as ds:\n",
    "                ds = convert_to_180(ds)\n",
    "                ds = ds.sel(\n",
    "                    time=slice(start_time, end_time)\n",
    "                )  # .sel(lat=slice(min_lat,max_lat), lon=slice(min_lon,max_lon))\n",
    "                ds = convert_time(ds)\n",
    "                ds_uas = get_data_within_LME(ds, \"uas\", LME, create_maps)\n",
    "                ds_vas = get_data_within_LME(ds, \"vas\", LME, create_maps)\n",
    "                ds_uas = ds_uas.mean({\"lat\", \"lon\"})\n",
    "                ds_vas = ds_vas.mean({\"lat\", \"lon\"})\n",
    "                df = ds_uas.to_dataframe().dropna()\n",
    "                df2 = ds_vas.to_dataframe().dropna()\n",
    "\n",
    "                df = df.reset_index()\n",
    "                df2 = df2.reset_index()\n",
    "\n",
    "                df[\"velocity\"] = np.sqrt(\n",
    "                    np.power(df[\"uas\"], 2) + np.power(df2[\"vas\"], 2)\n",
    "                )\n",
    "                df = df.reset_index()\n",
    "                df.drop(columns=[\"uas\", \"vas\"], inplace=True)\n",
    "        df = df.set_index(\"time\")\n",
    "\n",
    "        df = df.resample(frequency).mean()\n",
    "        df[\"model_name\"] = model\n",
    "        df[\"LME\"] = LME\n",
    "        df[\"roll_mean\"] = df[var_name].rolling(5).mean().shift(-1)\n",
    "        df[\"roll_std\"] = df[{var_name}].rolling(5).std().shift(-1)\n",
    "        df[\"roll_median\"] = df[var_name].rolling(5).median().shift(-1)\n",
    "        df[\"roll_max\"] = df[var_name].rolling(5).max().shift(-1)\n",
    "        df[\"roll_min\"] = df[var_name].rolling(5).min().shift(-1)\n",
    "\n",
    "        df[\"model_ensemble_id\"] = ensemble_id\n",
    "        df[\"model_scenario\"] = scenario\n",
    "        unique = \"{}_{}_{}\".format(model, scenario, ensemble_id)\n",
    "        df[\"unique\"] = unique\n",
    "\n",
    "        model_info = {}\n",
    "        model_info[\"model_name\"] = model\n",
    "        model_info[\"model_scenario\"] = scenario\n",
    "        model_info[\"model_ensemble_id\"] = ensemble_id\n",
    "        model_info[\"model_var\"] = var_name\n",
    "        model_info[\"LME\"] = LME\n",
    "        key = \"{}_{}_{}_{}\".format(model, ensemble_id, scenario, var_name)\n",
    "        if var_name in [\"TOZ\"]:\n",
    "            key = fname\n",
    "\n",
    "        formatter = \"{:.2f}\"\n",
    "        #   model_info[\"model_min\"]=formatter.format(np.nanmin(df[var_name]))\n",
    "        #   model_info[\"model_max\"]=formatter.format(np.nanmax(df[var_name]))\n",
    "\n",
    "        models_dict[key] = model_info\n",
    "\n",
    "        return df, models_dict, None\n",
    "    else:\n",
    "        return None, models_dict, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def get_LME_records():\n",
    "    lme_file = \"/Users/trondkr/Library/CloudStorage/Dropbox/NIVA/oceanography/Shapefiles/LME66/LMEs66.shp\"\n",
    "    return gpd.read_file(lme_file)\n",
    "\n",
    "\n",
    "def get_LME_records_plot():\n",
    "    lme_file = \"/Users/trondkr/Library/CloudStorage/Dropbox/NIVA/oceanography/Shapefiles/LME66_180/LME66_180.shp\"\n",
    "    return gpd.read_file(lme_file)\n",
    "\n",
    "\n",
    "def create_colors(N):\n",
    "    color = iter(cm.tab20b(np.linspace(0, 1, N)))\n",
    "    return [next(color) for c in range(N)]\n",
    "\n",
    "\n",
    "def create_map(df, title, var_name, period, anomalies=False, details=False):\n",
    "    if details is True:\n",
    "        lonmin = -165\n",
    "        lonmax = -143.5\n",
    "        latmin = 53.5\n",
    "        latmax = 65.0\n",
    "        res = \"10m\"\n",
    "    else:\n",
    "        lonmin = -252\n",
    "        lonmax = -100.5\n",
    "        latmin = 20\n",
    "        latmax = 80\n",
    "        res = \"50m\"\n",
    "    ax = plt.figure(figsize=(16, 10)).gca(\n",
    "        projection=cartopy.crs.PlateCarree(central_longitude=-180)\n",
    "    )\n",
    "\n",
    "    ax.coastlines(resolution=res, linewidth=0.6, color=\"black\", alpha=0.8, zorder=4)\n",
    "    ax.add_feature(cpf.BORDERS, linestyle=\":\", alpha=0.4)\n",
    "    ax.add_feature(cpf.LAND, color=\"lightgrey\")\n",
    "    ax.set_extent([lonmin, lonmax, latmin, latmax])\n",
    "\n",
    "    xticks = np.linspace(lonmin, lonmax, 5)\n",
    "    yticks = np.linspace(latmin, latmax, 5)\n",
    "\n",
    "    ax.set_xticks(xticks, crs=cartopy.crs.PlateCarree())\n",
    "    ax.set_yticks(yticks, crs=cartopy.crs.PlateCarree())\n",
    "    lon_formatter = LongitudeFormatter(zero_direction_label=True)\n",
    "    lat_formatter = LatitudeFormatter()\n",
    "    ax.xaxis.set_major_formatter(lon_formatter)\n",
    "    ax.yaxis.set_major_formatter(lat_formatter)\n",
    "\n",
    "    # if var_name in [\"par\"]:\n",
    "    clb_label = \"PAR ($W/m^{2}$)\"\n",
    "    cs = ax.contourf(\n",
    "        df[\"lon\"],\n",
    "        df[\"lat\"],\n",
    "        df[var_name],  # np.where(df[\"H\"] < 0, df[\"H\"], np.nan), # df[var_name],\n",
    "        cmap=sns.color_palette(\"Spectral_r\", as_cmap=True),\n",
    "        transform=ccrs.PlateCarree(),\n",
    "    )\n",
    "\n",
    "    if title not in [\"Bathymetry\"]:\n",
    "        clb = plt.colorbar(cs, shrink=0.5, extend=\"both\")\n",
    "\n",
    "    plt.xlabel(\"Longitude\")\n",
    "    plt.ylabel(\"Latitude\")\n",
    "\n",
    "    # if details:\n",
    "    #    plt.savefig(\"../../GOA-Laurel/Figures/Bottom_{}_july_sept_250m_zoomed_{}.png\".format(var_name, period), dpi=300,\n",
    "    #                facecolor='w',\n",
    "    #                transparent=False,\n",
    "    #                bbox_inches = 'tight',\n",
    "    #                pad_inches = 0)\n",
    "    # else:\n",
    "    #    plt.savefig(\"../../GOA-Laurel/Figures/Bottom_{}_july_sept_250m_{}.png\".format(var_name, period), dpi=300,\n",
    "    #            facecolor='w',\n",
    "    #                transparent=False,\n",
    "    #                bbox_inches = 'tight',\n",
    "    #                pad_inches = 0)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def create_LME_figure(ax, LMES, projection, show, extent):\n",
    "    ax.add_feature(cfeature.LAND)\n",
    "    ax.add_feature(cfeature.COASTLINE)\n",
    "\n",
    "    ax.set_extent(extent)\n",
    "\n",
    "    # Get the -180-180 projected shapefile containing LMEs to make it\n",
    "    # easy to plot across the Pacific Ocean\n",
    "    shdf = get_LME_records_plot()\n",
    "    colors_rgb = create_colors(len(LMES))\n",
    "    counter = 0\n",
    "    for LME_NAME, LME_NUMBER in zip(shdf[\"LME_NAME\"], shdf[\"LME_NUMBER\"]):\n",
    "        shdf_sel = shdf[shdf[\"LME_NAME\"] == LME_NAME]\n",
    "\n",
    "        if LME_NAME in LMES:\n",
    "            # print(\"Adding geometry for LME {}\".format(LME_NAME))\n",
    "            # Add the geometry and fill it with color\n",
    "            if len(LMES) == 1:\n",
    "                color = \"red\"\n",
    "            else:\n",
    "                color = colors_rgb[counter]\n",
    "            ax.add_geometries(\n",
    "                shdf_sel[\"geometry\"], projection, facecolor=color, edgecolor=\"k\"\n",
    "            )\n",
    "\n",
    "            # Add the label LME_NUMBER of the selected LME at the center of the LME\n",
    "            #  ax.annotate(s=LME_NUMBER,\n",
    "            #              xy=(shdf_sel.centroid.x,shdf_sel.centroid.y),\n",
    "            #              color=\"white\",\n",
    "            #              fontsize=13)\n",
    "            counter += 1\n",
    "        else:\n",
    "            ax.add_geometries(\n",
    "                shdf_sel[\"geometry\"], projection, facecolor=\"LightGray\", edgecolor=\"k\"\n",
    "            )\n",
    "\n",
    "    if show:\n",
    "        plotfile = \"Figures/CMIP6_lightpaper_map_{}.png\".format(LMES[0])\n",
    "        print(\"Created figure {}\".format(plotfile))\n",
    "        plt.savefig(plotfile, dpi=200, bbox_inches=\"tight\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def get_data_within_LME(ds, var_name, LME, create_maps):\n",
    "    print(\"Working on LME: {}\".format(LME))\n",
    "\n",
    "    # Extract the polygon defining the boundaries of the LME\n",
    "    shdf = get_LME_records()\n",
    "    # for name in shdf['LME_NAME']:\n",
    "    #     print(name)\n",
    "    shdf_sel = shdf[shdf[\"LME_NAME\"] == LME]\n",
    "\n",
    "    # Create the map of the LME bopundaries and color it.\n",
    "    # The active LME has color while the others are grey.\n",
    "    if create_maps:\n",
    "        # Setup the figure panels\n",
    "        fig = plt.figure(figsize=(13, 8))\n",
    "        if LME in [\"Barents Sea\", \"Arctic Ocean\"]:\n",
    "            projection = (\n",
    "                ccrs.NorthPolarStereo()\n",
    "            )  # ccrs.PlateCarree(central_longitude=0)\n",
    "            extent = [-20, 90, 60, 90]\n",
    "        #       extent = [-180, 180, 60, 90]\n",
    "        else:\n",
    "            projection = ccrs.PlateCarree(central_longitude=-180)\n",
    "            extent = [-252, -100, 10, 65]\n",
    "            extent = [-200, -145, 40, 80]\n",
    "        ax1 = fig.add_subplot(111, projection=projection)\n",
    "\n",
    "        create_LME_figure(\n",
    "            ax1, [LME], ccrs.PlateCarree(central_longitude=-180), True, extent\n",
    "        )\n",
    "\n",
    "    # Rioxarray requires x and y dimensions - we convert these back to lon and lat later.\n",
    "    # We also add the projection (lat-lon) so that rioxarray can do the clipping of the data according to the\n",
    "    # shapefile.\n",
    "\n",
    "    tos = ds.rename({\"lon\": \"x\", \"lat\": \"y\"})\n",
    "    tos = tos.rio.write_crs(4326)\n",
    "\n",
    "    # Clip the data within the LME. We have to convert the polygon geometry to a geodataframe using\n",
    "    # `shapely.geometry`. The clipping of data within the polygon is done using rioxarray.clip function\n",
    "\n",
    "    clipped = tos.rio.clip(geometries=shdf_sel.geometry.apply(mapping), crs=tos.rio.crs)\n",
    "    clipped = clipped.rename({\"x\": \"lon\", \"y\": \"lat\"})  # .to_dataset()\n",
    "\n",
    "    p1 = \"2000-01-01 to 2020-01-01\"\n",
    "    p2 = \"2080-01-01 to 2020-01-01\"\n",
    "\n",
    "    create_maps = False\n",
    "    if create_maps:\n",
    "        clipped_p1 = clipped.sel(time=slice(\"2000-01-01\", \"2020-01-01\")).mean({\"time\"})\n",
    "        # clipped_p2=clipped.sel(time=slice(\"2080-01-01\",\"2099-12-16\")).mean({\"time\"})\n",
    "\n",
    "        create_map(\n",
    "            clipped_p1,\n",
    "            \"{} 2000-01-01 to 2020-01-01\".format(var_name),\n",
    "            var_name,\n",
    "            period=p1,\n",
    "            anomalies=False,\n",
    "            details=False,\n",
    "        )\n",
    "        # create_map(clipped_p2, \"{} 2080-01-01 to 2020-01-01\".format(var_name), var_name, period=p2, anomalies=False, details=False)\n",
    "\n",
    "        plt.show()\n",
    "    return clipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def create_summary_table(dict_of_models, LME):\n",
    "    table = texttable.Texttable()\n",
    "    table.set_cols_align([\"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\"])\n",
    "    table.set_cols_valign([\"t\", \"t\", \"m\", \"m\", \"m\", \"m\", \"b\"])\n",
    "\n",
    "    table.header([\"LME\", \"Model\", \"Scenario\", \"ID\", \"Var\", \"CMIP6 min\", \"CMIP6 max\"])\n",
    "    for key in dict_of_models.keys():\n",
    "        model = dict_of_models[key]\n",
    "\n",
    "        table.add_row(\n",
    "            [\n",
    "                LME,\n",
    "                model[\"model_name\"],\n",
    "                model[\"model_scenario\"],\n",
    "                model[\"model_ensemble_id\"],\n",
    "                str(model[\"model_var\"]),\n",
    "                str(model[\"model_var\"]),\n",
    "                str(model[\"model_var\"]),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    table.set_cols_width([30, 30, 20, 20, 10, 10, 10])\n",
    "    print(table.draw() + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_netcdf(ds: xr.Dataset, out_file: str) -> None:\n",
    "    enc = {}\n",
    "\n",
    "    for k in ds.data_vars:\n",
    "        if ds[k].ndim < 2:\n",
    "            continue\n",
    "\n",
    "        enc[k] = {\n",
    "            \"zlib\": True,\n",
    "            \"complevel\": 3,\n",
    "            \"fletcher32\": True,\n",
    "            \"chunksizes\": tuple(map(lambda x: x // 2, ds[k].shape)),\n",
    "        }\n",
    "\n",
    "    ds.to_netcdf(out_file, format=\"NETCDF4\", engine=\"netcdf4\", encoding=enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "scenarios=[\"ssp245\",\"ssp585\"]\n",
    "member_range=10\n",
    "frequency=\"A\"\n",
    "\n",
    "# Create objects to reuse functionality to open files on Google Cloud storage\n",
    "io = CMIP6_IO()\n",
    "config = Config_albedo()\n",
    "\n",
    "#ensemble_ids = [\"r10i1p1f1\", \"r4i1p1f1\", \"r10i1p2f1\", \"r3i1p2f1\", \"r2i1p1f2\",#\"r4i1p1f2\",\"r2i1p1f1\"]\n",
    "period=\"1950-01-01-2099-12-16\"\n",
    "start_time=\"1950-01-01\"\n",
    "end_time=\"2099-12-16\"\n",
    "\n",
    "# FOR RTM we are using:\n",
    "# \"CMCC-ESM2\": [\"r1i1p1f1\",\"r1i1p2f1\"]\n",
    "# \"CanESM5\":  [\"r1i1p2f1\",\"r2i1p2f1\",\"r9i1p2f1\",\"r10i1p2f1\",\"r7i1p2f1\"]\n",
    "# \"MPI-ESM1-2-LR\": [\"r10i1p1f1\",\"r1i1p1f1\",\"r4i1p1f1\",\"r2i1p1f1\"]\n",
    "# \"UKESM1-0-LL\": [\"r1i1p1f2\",\"r2i1p1f2\",\"r3i1p1f2\",\"r4i1p1f2\",\"r8i1p1f2\"]\n",
    "# \"MPI-ESM1-2-HR\": [\"r1i1p1f1\",\"r2i1p1f1\"]\n",
    "        \n",
    "models=[\"CMCC-ESM2\",\"CanESM5\", \"MPI-ESM1-2-LR\", \"UKESM1-0-LL\", \"MPI-ESM1-2-HR\"]\n",
    "ensemble_ids=[[\"r1i1p2f1\"],\n",
    "              [\"r1i1p2f1\",\"r2i1p2f1\",\"r9i1p2f1\",\"r10i1p2f1\",\"r7i1p2f1\"],\n",
    "              [\"r10i1p1f1\",\"r1i1p1f1\",\"r4i1p1f1\",\"r2i1p1f1\"],\n",
    "              [\"r1i1p1f2\",\"r2i1p1f2\",\"r3i1p1f2\",\"r4i1p1f2\",\"r8i1p1f2\"],\n",
    "              [\"r1i1p1f1\",\"r2i1p1f1\"]]\n",
    "\n",
    "ds_var_names=[\"velocity\",\"chl\", \"clt\", \"sithick\", \"siconc\", \"tas\",\"chl\"]\n",
    "ds_var_names=[\"chl\", \"clt\"] \n",
    "ds_var_names = [\"prw\",\n",
    "            \"clt\",\n",
    "            \"uas\",\n",
    "            \"vas\",\n",
    "            \"chl\",\n",
    "            \"sithick\",\n",
    "            \"siconc\",\n",
    "            \"sisnthick\",\n",
    "            \"sisnconc\",\n",
    "            \"tas\",\n",
    "            \"tos\"]\n",
    "\n",
    "LMES=['Barents Sea','Northern Bering - Chukchi Seas']\n",
    "toz_list=[]\n",
    "config.source_ids = models\n",
    "ensemble_ids_flat = [item for it in ensemble_ids for item in it]\n",
    "\n",
    "config.member_ids=ensemble_ids_flat\n",
    "\n",
    "for experiment_id in [\"ssp245\"]:\n",
    "    io.organize_cmip6_netcdf_files_into_datasets(config, experiment_id)\n",
    "\n",
    "    for varname in ds_var_names:\n",
    "        all_ds = []\n",
    "        for model in io.models:\n",
    "            for mids in model.member_ids:\n",
    "                for ds_var in model.ocean_vars[mids]:\n",
    "                    \n",
    "                    if ds_var==varname:\n",
    "                    \n",
    "                        all_ds.append(model.ds_sets[mids][varname])\n",
    "                        \n",
    "                if len(all_ds) > 0:\n",
    "                    ens = ensembles.create_ensemble(all_ds, multifile=False, backend='zarr')\n",
    "                    dir = config.cmip6_netcdf_dir\n",
    "                    ensemble_filename = io.format_netcdf_filename(dir, \"ensemble\", \"\", experiment_id, varname)\n",
    "                    Path(ensemble_filename).parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "                    write_netcdf(ens, ensemble_filename)\n",
    "                    io.upload_to_gcs(ensemble_filename)\n",
    "                    print(\"ens\", ens, ensemble_filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \"\"\"\n",
    "    for LME in LMES:\n",
    "        df_list=[]\n",
    "        models_dict={}\n",
    "        create_maps=False\n",
    "        # We loop over all of the scenarios, ensemble_ids, and models to create a\n",
    "        # list of dataframes that we eventually concatenate together and plot\n",
    "        for scenario in scenarios:\n",
    "            ds_list=[]\n",
    "            for model in models:\n",
    "                for ensemble_id in ensemble_ids:\n",
    "                    io.format_netcdf_filename(dir, model_name, member_id, current_experiment_id, key)\n",
    "                    if var_name in [\"TOZ\"]:\n",
    "                        fname = \"/Users/trondkr/Library/CloudStorage/Dropbox/NIVA/oceanography/cmip6/light/ozone-absorption/TOZ_{}.nc\".format(scenario)\n",
    "                        fname2=None\n",
    "\n",
    "                    elif var_name not in [\"velocity\", \"TOZ\"]:\n",
    "                        fname = \"/Users/trondkr/Library/CloudStorage/Dropbox/NIVA/oceanography/cmip6/light/{}/{}/CMIP6_{}_{}_{}_{}.nc\".format(scenario,model,\n",
    "                                                                                             model,\n",
    "                                                                                             ensemble_id,\n",
    "                                                                                             scenario,\n",
    "                                                                                             var_name)\n",
    "                        fname2=None\n",
    "\n",
    "                    elif var_name in [\"velocity\"]:\n",
    "                        fname = \"/Users/trondkr/Library/CloudStorage/Dropbox/NIVA/oceanography/cmip6/light/{}/{}/CMIP6_{}_{}_{}_{}.nc\".format(scenario,model,\n",
    "                                                                                         model,\n",
    "                                                                                         ensemble_id,\n",
    "                                                                                         scenario,\n",
    "                                                                                         \"uas\")\n",
    "                        fname2 = \"/Users/trondkr/Library/CloudStorage/Dropbox/NIVA/oceanography/cmip6/light/{}/{}/CMIP6_{}_{}_{}_{}.nc\".format(scenario,model,\n",
    "                                                                                         model,\n",
    "                                                                                         ensemble_id,\n",
    "                                                                                         scenario,\n",
    "                                                                                             \"vas\")\n",
    "                    key=\"{}_{}_{}_{}\".format(model,ensemble_id,scenario,var_name)\n",
    "                    if var_name in [\"TOZ\"]:\n",
    "                        key=fname\n",
    "\n",
    "                    if key not in models_dict.keys():\n",
    "\n",
    "                        df, models_dict, ds_lme = get_area_averaged_ds(fname, model,scenario, ensemble_id,var_name, LME, create_maps, frequency, models_dict,fname2)\n",
    "                        create_maps=False\n",
    "                        if ds_lme is not None:\n",
    "                          #  ds_lme=xr.where( ((ds_lme < 1.e-3)| (ds_lme > 1e3)), np.nan, ds_lme)\n",
    "                           # ds_lme=xr.where(ds_lme < 1, np.nan, ds_lme)\n",
    "                            ds_list.append(ds_lme)\n",
    "\n",
    "                        if df is not None:\n",
    "\n",
    "                            df_list.append(df)\n",
    "                            if var_name in [\"TOZ\"]:\n",
    "                                toz_list.append(df)\n",
    "                            print(\"Created dataframe of file: {}\".format(fname))\n",
    "\n",
    "            if len(ds_list) > 0:\n",
    "                ens = ensembles.create_ensemble(ds_list).load()\n",
    "                ens.close()\n",
    "                ens_stats = ensembles.ensemble_mean_std_max_min(ens)\n",
    "\n",
    "                outfile = \"Figures/{}_ensemble_{}_{}.png\".format(var_name.capitalize(),scenario, LME)\n",
    "\n",
    "              #  CMIP6_ridgeplot.ridgeplot(\"{}_mean\".format(var_name),\n",
    "              #                            None, outfile,\n",
    "              #                                    glorys=False, depth_threshold=None,\n",
    "              #                                    ds=ens_stats)\n",
    "\n",
    "\n",
    "        if len(df_list) > 0:\n",
    "            df = pd.concat(df_list)\n",
    "\n",
    "            create_summary_table(models_dict, LME)\n",
    "            df = df.reindex()\n",
    "            df[\"date\"]=df.index\n",
    "\n",
    "            if os.path.exists(\"test.csv\"):os.remove(\"test.csv\")\n",
    "            df.to_csv(\"test.csv\")\n",
    "            df = pd.read_csv('test.csv', parse_dates=['time', 'date'])\n",
    "            \n",
    "            \n",
    "            sns.set(style=\"white\", rc={\"axes.facecolor\": (0, 0, 0, 0)}, font_scale=1.5)\n",
    "            f=plt.figure(figsize=(16, 16))\n",
    "            gs = f.add_gridspec(2, 1)\n",
    "            ax = f.add_subplot(gs[0, 0])\n",
    "\n",
    "            sns.set_palette([\"#8172B3\", \"#64B5CD\"])\n",
    "            legend_on=True if var_name==\"tas\" else False\n",
    "\n",
    "            b=sns.lineplot(ax=ax, data=df, x=df[\"date\"], y=df[\"roll_mean\"],\n",
    "                         hue=df[\"model_scenario\"],palette= [\"#8172B3\", \"#64B5CD\"],\n",
    "                         alpha=.95, ci=95,linewidth=5, legend=legend_on)\n",
    "\n",
    "            cycle_colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "            df_ssp245=df[df[\"model_scenario\"]==\"ssp245\"]\n",
    "            ax.fill_between(df_ssp245[\"date\"], df_ssp245[\"roll_mean\"] - df_ssp245[\"roll_std\"], df_ssp245[\"roll_mean\"] + df_ssp245[\"roll_std\"], color=cycle_colors[0], alpha=0.2)\n",
    "            df_ssp585=df[df[\"model_scenario\"]==\"ssp585\"]\n",
    "            ax.fill_between(df_ssp585[\"date\"], df_ssp585[\"roll_mean\"] - df_ssp585[\"roll_std\"], df_ssp585[\"roll_mean\"] + df_ssp585[\"roll_std\"], color=cycle_colors[1], alpha=0.2)\n",
    "            print(df_ssp245.head())\n",
    "            print(\"ssp245\",((df_ssp245[\"roll_mean\"][-1]-df_ssp245[\"roll_mean\"][0])/df_ssp245[\"roll_mean\"][0])*100.)\n",
    "            print(\"ssp585\",((df_ssp585[\"roll_mean\"][-1]-df_ssp585[\"roll_mean\"][0])/df_ssp585[\"roll_mean\"][0])*100.)\n",
    "\n",
    "            b.tick_params(labelsize=38)\n",
    "            b.set_xlabel(\"\",fontsize=34)\n",
    "            b.set_ylabel(\"\",fontsize=34)\n",
    "            import matplotlib.dates as mdates\n",
    "            if var_name==\"tas\":\n",
    "                plt.legend(loc=\"upper left\", frameon=False, fontsize=32)\n",
    "\n",
    "            ax.xaxis.set_major_locator(mdates.YearLocator(base=10))\n",
    "            ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "            plt.setp(ax.xaxis.get_majorticklabels(), rotation=-90)\n",
    "\n",
    "            if not os.path.exists(\"Figures\"):\n",
    "                os.makedirs(\"Figures\")\n",
    "            plotfile=\"Figures/CMIP6_lightpaper_{}_{}.png\".format(var_name,LME)\n",
    "            print(\"Created figure {}\".format(plotfile))\n",
    "            plt.savefig(plotfile, dpi=300,\n",
    "                        bbox_inches = 'tight')\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "        df=pd.DataFrame()\n",
    "        ds_list=[]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the relative change in chlorophyll production between 1980-2000 and\n",
    "# and 2080-2099 for each model scenario.\n",
    "df = pd.read_csv(\"test.csv\", parse_dates=[\"time\", \"date\"])\n",
    "\n",
    "df_ssp245 = df[df[\"model_scenario\"] == \"ssp245\"].dropna()\n",
    "df_ssp585 = df[df[\"model_scenario\"] == \"ssp585\"].dropna()\n",
    "df_ssp585 = df_ssp585.reset_index()\n",
    "clim245 = (df_ssp245[\"roll_mean\"].loc[\"1980-01-01\":\"2000-01-01\"]).mean(skipna=True)\n",
    "clim585 = (df_ssp585[\"roll_mean\"].loc[\"1980-01-01\":\"2000-01-01\"]).mean(skipna=True)\n",
    "std = (df_ssp245[\"roll_mean\"].loc[\"2080-01-01\":\"2099-01-01\"]).mean(skipna=True) + (\n",
    "    df_ssp245[\"roll_std\"].loc[\"2080-01-01\":\"2099-01-01\"]\n",
    ").mean(skipna=True)\n",
    "std585 = (df_ssp585[\"roll_mean\"].loc[\"2080-01-01\":\"2099-01-01\"]).mean(skipna=True) + (\n",
    "    df_ssp585[\"roll_std\"].loc[\"2080-01-01\":\"2099-01-01\"]\n",
    ").mean(skipna=True)\n",
    "\n",
    "df_ssp245[\"rel_change_std\"] = ((std - float(clim245)) / float(clim245)) * 100.0\n",
    "df_ssp245[\"rel_change\"] = (\n",
    "    (\n",
    "        (df_ssp245[\"roll_mean\"].loc[\"2080-01-01\":\"2099-01-01\"]).mean(skipna=True)\n",
    "        - float(clim245)\n",
    "    )\n",
    "    / float(clim245)\n",
    ") * 100.0\n",
    "\n",
    "df_ssp585[\"rel_change_std\"] = ((std585 - float(clim245)) / float(clim245)) * 100.0\n",
    "df_ssp585[\"rel_change\"] = (\n",
    "    (\n",
    "        df_ssp585[\"roll_mean\"].loc[\"2080-01-01\":\"2099-01-01\"].mean(skipna=True)\n",
    "        - float(clim245)\n",
    "    )\n",
    "    / float(clim245)\n",
    ") * 100.0\n",
    "print(df_ssp245[[\"time\", \"rel_change\", \"rel_change_std\"]])\n",
    "print(df_ssp585[[\"time\", \"rel_change\", \"rel_change_std\"]])\n",
    "sns.lineplot(y=\"roll_mean\", x=\"time\", data=df_ssp245)\n",
    "sns.lineplot(y=\"roll_mean\", x=\"time\", data=df_ssp585)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
