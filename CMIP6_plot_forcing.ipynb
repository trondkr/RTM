{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.style.use(\"default\")\n",
    "from pathlib import Path\n",
    "import cftime\n",
    "import os, sys\n",
    "import seaborn as sns\n",
    "import cartopy\n",
    "import cartopy.feature as cpf\n",
    "from global_land_mask import globe\n",
    "import CMIP6_light_map\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from shapely.geometry import box, mapping\n",
    "import geopandas as gpd\n",
    "import rioxarray\n",
    "from matplotlib import cm\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n",
    "import matplotlib.dates as mdates\n",
    "import global_land_mask\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "sys.path.append(\"../CMIP6_downscale/\")\n",
    "from CMIP6_ridgeplot import CMIP6_ridgeplot\n",
    "from xclim import ensembles\n",
    "from CMIP6_IO import CMIP6_IO\n",
    "from CMIP6_config import Config_albedo"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "def get_LME_records():\n",
    "    lme_file = \"gs://actea-shared/Shapefiles/LME66/LMEs66.shp\"\n",
    "    return gpd.read_file(lme_file)\n",
    "\n",
    "\n",
    "def get_LME_records_plot():\n",
    "    lme_file = \"gs://actea-shared/Shapefiles/LME66_180/LME66_180.shp\"\n",
    "    return gpd.read_file(lme_file)\n",
    "\n",
    "\n",
    "def create_colors(N):\n",
    "    color = iter(cm.tab20b(np.linspace(0, 1, N)))\n",
    "    return [next(color) for c in range(N)]\n",
    "\n",
    "\n",
    "def get_data_within_LME(ds, var_name, LME, create_maps):\n",
    "    # Extract the polygon defining the boundaries of the LME\n",
    "    print(f\"Working on LME: {LME}\")\n",
    "\n",
    "    if LME == \"Northern Bering - Chukchi Seas\":\n",
    "        shdf = get_LME_records_plot()\n",
    "    elif LME == \"Barents Sea\":\n",
    "        shdf = get_LME_records()\n",
    "    else:\n",
    "        raise Exception(f\"Unable to parse LME {LME}\")\n",
    "\n",
    "    shdf_sel = shdf[shdf[\"LME_NAME\"] == LME]\n",
    "\n",
    "    # Rioxarray requires x and y dimensions - we convert these back to lon and lat later.\n",
    "    # We also add the projection (lat-lon) so that rioxarray can do the clipping of the data according to the\n",
    "    # shapefile.\n",
    "    if var_name not in [\"TOZ\"]:\n",
    "        ds = ds.rename({\"x\": \"lon\", \"y\": \"lat\"})\n",
    "    ds = ds.rio.write_crs(4326)\n",
    "\n",
    "    ds.rio.set_spatial_dims(y_dim=\"lat\", x_dim=\"lon\", inplace=True)\n",
    "    ds.rio.write_crs(4326, inplace=True)\n",
    "\n",
    "    clipped = ds.rio.clip(geometries=shdf_sel.geometry.apply(mapping), crs=ds.rio.crs)\n",
    "    if \"x\" in ds.dims:\n",
    "        clipped = clipped.rename({\"x\": \"lon\", \"y\": \"lat\"})\n",
    "    return clipped"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "def convert_to_180(ds, LME, var_name):\n",
    "    print(ds)\n",
    "    # We need to rename and reorganize the dimensions and names for spatial\n",
    "    # coordinates to work with geopandas.\n",
    "    if var_name == \"TOZ\":\n",
    "        ds = ds.assign_coords(lat=ds.lat.values, lon=ds.lon.values)\n",
    "    else:\n",
    "        ds = ds.assign_coords(lat=ds.lat[:, 0].values, lon=ds.lon[0, :].values)\n",
    "    if LME == \"Northern Bering - Chukchi Seas\":\n",
    "        ds = (ds.assign_coords(lon=(((ds.lon + 180) % 360) - 180))).sortby(\"lon\")\n",
    "\n",
    "    return ds\n",
    "\n",
    "\n",
    "def convert_time(ds):\n",
    "    if not ds.indexes[\"time\"].dtype in [\"datetime64[ns]\"]:\n",
    "        time_objects = ds.indexes[\"time\"].to_datetimeindex()\n",
    "        ds = ds.assign_coords({\"time\": time_objects})\n",
    "        ds = xr.decode_cf(ds)\n",
    "\n",
    "    return ds\n",
    "\n",
    "\n",
    "def get_area_averaged_ds(\n",
    "    model,\n",
    "    experiment_id,\n",
    "    ds,\n",
    "    var_name,\n",
    "    LME,\n",
    "    create_maps,\n",
    "    outfile_name,\n",
    "    frequency,\n",
    "    start_time,\n",
    "    end_time,\n",
    "):\n",
    "    # Frequency of smoothing the plots. This is the number of years to smooth over\n",
    "    # if frequency is Annual.\n",
    "    roll_frequency = 1\n",
    "\n",
    "    ds = convert_to_180(ds, LME, var_name)\n",
    "\n",
    "    ds = ds.sel(time=slice(start_time, end_time))\n",
    "    ds = convert_time(ds)\n",
    "    if var_name in [\"tas\"]:\n",
    "        ds = xr.where(ds > 100, ds - 273.15, ds)\n",
    "\n",
    "    # Convert from kg/m-3 to mg/m-3\n",
    "    # if var_name in [\"chl\"]:\n",
    "    #  ds[var_name]=ds[var_name]/1.0e6\n",
    "\n",
    "    ds_lme = get_data_within_LME(ds, var_name, LME, create_maps)\n",
    "    outfile = f\"Figures/{var_name}_{experiment_id}_ridgeplot_{LME}.png\"\n",
    "    if Path(outfile).exists():\n",
    "        Path(outfile).unlink()\n",
    "    CMIP6_ridgeplot.ridgeplot(\n",
    "        var_name, None, outfile, glorys=False, depth_threshold=None, ds=ds_lme\n",
    "    )\n",
    "\n",
    "    ds = ds_lme.mean({\"lat\", \"lon\"}, skipna=True)\n",
    "\n",
    "    if var_name in [\"TOZ\"]:\n",
    "        ds = ds.assign(TOZ_std=ds_lme[var_name].std({\"lat\", \"lon\"}))\n",
    "    dfstd = ds[f\"{var_name}_stdev\"].to_dataframe().dropna().reset_index()\n",
    "    dfmean = ds[f\"{var_name}_mean\"].to_dataframe().dropna().reset_index()\n",
    "\n",
    "    df = dfmean\n",
    "    df[\"mean\"] = dfmean[f\"{var_name}_mean\"]\n",
    "    df[\"std\"] = dfstd[f\"{var_name}_stdev\"]\n",
    "\n",
    "    df = df.reset_index()\n",
    "    df = df.set_index(\"time\")\n",
    "\n",
    "    df = df.resample(frequency).mean()\n",
    "    df[\"model_name\"] = model\n",
    "    df[\"LME\"] = LME\n",
    "    df[\"roll_mean\"] = df[\"mean\"].rolling(roll_frequency).mean(skipna=True)\n",
    "    df[\"roll_std\"] = df[\"std\"].rolling(roll_frequency).mean(skipna=True)\n",
    "\n",
    "    df[\"model_scenario\"] = experiment_id\n",
    "    unique = \"{}_{}\".format(model, experiment_id)\n",
    "    df[\"unique\"] = unique\n",
    "\n",
    "    model_info = {}\n",
    "    model_info[\"model_name\"] = model\n",
    "    model_info[\"model_scenario\"] = experiment_id\n",
    "    model_info[\"model_var\"] = var_name\n",
    "    model_info[\"LME\"] = LME\n",
    "\n",
    "    return df, model_info"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "source": [
    "def calculate_velocity(df_uas: pd.DataFrame, df_vas: pd.DataFrame):\n",
    "    print(\"calculate_velocity\")\n",
    "\n",
    "    u_ssp245 = df_uas[\"ssp245\"]\n",
    "    u_ssp585 = df_uas[\"ssp585\"]\n",
    "\n",
    "    v_ssp245 = df_vas[\"ssp245\"]\n",
    "    v_ssp585 = df_vas[\"ssp585\"]\n",
    "\n",
    "    df_ssp245 = u_ssp245\n",
    "    df_ssp585 = u_ssp585\n",
    "\n",
    "    df_ssp245[\"mean\"] = np.sqrt(\n",
    "        np.power(u_ssp245[\"mean\"], 2) + np.power(v_ssp245[\"mean\"], 2)\n",
    "    )\n",
    "    df_ssp245[\"std\"] = np.sqrt(\n",
    "        np.power(u_ssp245[\"std\"], 2) + np.power(v_ssp245[\"std\"], 2)\n",
    "    )\n",
    "\n",
    "    df_ssp585[\"mean\"] = np.sqrt(\n",
    "        np.power(u_ssp585[\"mean\"], 2) + np.power(v_ssp585[\"mean\"], 2)\n",
    "    )\n",
    "    df_ssp585[\"std\"] = np.sqrt(\n",
    "        np.power(u_ssp585[\"std\"], 2) + np.power(v_ssp585[\"std\"], 2)\n",
    "    )\n",
    "\n",
    "    df_ssp585 = df_ssp585.reset_index()\n",
    "    df_ssp245 = df_ssp245.reset_index()\n",
    "\n",
    "    return df_ssp245, df_ssp585\n",
    "\n",
    "\n",
    "def create_timeseries_for_lme(\n",
    "    varname: str, df: [pd.DataFrame], LME: str, stored_uas=None\n",
    "):\n",
    "    if stored_uas is None:\n",
    "        df_ssp245 = df[\"ssp245\"]\n",
    "        df_ssp585 = df[\"ssp585\"]\n",
    "    else:\n",
    "        varname = \"velocity\"\n",
    "        df_ssp245, df_ssp585 = calculate_velocity(stored_uas, df)\n",
    "\n",
    "    df_ssp245[\"date\"] = df_ssp245.index\n",
    "    df_ssp585[\"date\"] = df_ssp585.index\n",
    "    sns.set(style=\"white\", rc={\"axes.facecolor\": (0, 0, 0, 0)}, font_scale=1.3)\n",
    "    f = plt.figure(figsize=(16, 16))\n",
    "    gs = f.add_gridspec(2, 1)\n",
    "    ax = f.add_subplot(gs[0, 0])\n",
    "\n",
    "    sns.set_palette([\"#8172B3\", \"#64B5CD\"])\n",
    "    legend_on = True if varname == \"tas\" else False\n",
    "\n",
    "    b = sns.lineplot(\n",
    "        ax=ax,\n",
    "        data=df_ssp245,\n",
    "        x=df_ssp245[\"date\"],\n",
    "        y=df_ssp245[\"roll_mean\"],\n",
    "        hue=df_ssp245[\"model_scenario\"],\n",
    "        palette=[\"#8172B3\"],\n",
    "        alpha=0.95,\n",
    "        ci=95,\n",
    "        linewidth=5,\n",
    "        legend=legend_on,\n",
    "    )\n",
    "\n",
    "    b = sns.lineplot(\n",
    "        ax=ax,\n",
    "        data=df_ssp585,\n",
    "        x=df_ssp585[\"date\"],\n",
    "        y=df_ssp585[\"roll_mean\"],\n",
    "        hue=df_ssp585[\"model_scenario\"],\n",
    "        palette=[\"#64B5CD\"],\n",
    "        alpha=0.95,\n",
    "        ci=95,\n",
    "        linewidth=5,\n",
    "        legend=legend_on,\n",
    "    )\n",
    "\n",
    "    cycle_colors = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n",
    "\n",
    "    ax.fill_between(\n",
    "        df_ssp245[\"date\"],\n",
    "        df_ssp245[\"roll_mean\"] - df_ssp245[\"roll_std\"],\n",
    "        df_ssp245[\"roll_mean\"] + df_ssp245[\"roll_std\"],\n",
    "        color=cycle_colors[0],\n",
    "        alpha=0.2,\n",
    "    )\n",
    "\n",
    "    ax.fill_between(\n",
    "        df_ssp585[\"date\"],\n",
    "        df_ssp585[\"roll_mean\"] - df_ssp585[\"roll_std\"],\n",
    "        df_ssp585[\"roll_mean\"] + df_ssp585[\"roll_std\"],\n",
    "        color=cycle_colors[1],\n",
    "        alpha=0.2,\n",
    "    )\n",
    "\n",
    "    b.tick_params(labelsize=30)\n",
    "    b.set_xlabel(\"\", fontsize=30)\n",
    "    b.set_ylabel(\"\", fontsize=30)\n",
    "\n",
    "    if varname in [\"sithick\", \"siconc\", \"sisnconc\", \"sisnconc\"]:\n",
    "        plt.ylim(0.0, None)\n",
    "\n",
    "    if varname == \"tas\":\n",
    "        plt.legend(loc=\"upper left\", frameon=False, fontsize=32)\n",
    "\n",
    "    ax.xaxis.set_major_locator(mdates.YearLocator(base=10))\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y\"))\n",
    "    plt.setp(ax.xaxis.get_majorticklabels(), rotation=-90)\n",
    "\n",
    "    if not os.path.exists(\"Figures\"):\n",
    "        os.makedirs(\"Figures\")\n",
    "    plotfile = f\"Figures/CMIP6_lightpaper_{varname}_{LME}.png\"\n",
    "    print(f\"Created figure {plotfile}\")\n",
    "    plt.savefig(plotfile, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "%%time\n",
    "experiment_ids = [\"ssp245\", \"ssp585\"]\n",
    "frequency = \"A\"\n",
    "\n",
    "# Create objects to reuse functionality to open files on Google Cloud storage\n",
    "config = Config_albedo()\n",
    "create_maps = False\n",
    "\n",
    "period = \"1979-01-01-2099-12-16\"\n",
    "start_time = \"1979-01-01\"\n",
    "end_time = \"2099-12-16\"\n",
    "\n",
    "ds_var_names = [\n",
    "    \"prw\",\n",
    "    \"clt\",\n",
    "    \"chl\",\n",
    "    \"sithick\",\n",
    "    \"siconc\",\n",
    "    \"sisnthick\",\n",
    "    \"sisnconc\",\n",
    "    \"tas\",\n",
    "    \"tos\",\n",
    "]\n",
    "#      \"uas\",\n",
    "#      \"vas\"]\n",
    "\n",
    "ds_var_names = [\"TOZ\"]\n",
    "\n",
    "LMES = [\"Northern Bering - Chukchi Seas\", \"Barents Sea\"]\n",
    "toz_list = []\n",
    "for LME in LMES:\n",
    "    stored_uas = None\n",
    "    for varname in ds_var_names:\n",
    "        all_dfs = {}\n",
    "\n",
    "        for experiment_id in experiment_ids:\n",
    "            all_ds = []\n",
    "            ens_stats = None\n",
    "\n",
    "            io = CMIP6_IO()\n",
    "            direc = \"light\"\n",
    "            if varname == \"TOZ\":\n",
    "                ensemble_filename_stats = (\n",
    "                    f\"light/{experiment_id}/TOZ_{experiment_id}.nc\"\n",
    "                )\n",
    "            else:\n",
    "                ensemble_filename_stats = io.format_netcdf_filename(\n",
    "                    direc, \"ensemble\", \"\", experiment_id, varname\n",
    "                )\n",
    "\n",
    "            ens_stats = io.open_dataset_on_gs(ensemble_filename_stats)\n",
    "\n",
    "            outfile_name = ensemble_filename_stats.replace(\".nc\", f\"_{LME}.png\")\n",
    "\n",
    "            df, models_dict = get_area_averaged_ds(\n",
    "                \"ensemble\",\n",
    "                experiment_id,\n",
    "                ens_stats,\n",
    "                varname,\n",
    "                LME,\n",
    "                create_maps,\n",
    "                outfile_name,\n",
    "                frequency,\n",
    "                start_time,\n",
    "                end_time,\n",
    "            )\n",
    "\n",
    "            all_dfs[experiment_id] = df\n",
    "\n",
    "        if varname == \"uas\":\n",
    "            print(\"Storing uas\", stored_uas)\n",
    "            stored_uas = all_dfs.copy()\n",
    "\n",
    "        create_timeseries_for_lme(varname, all_dfs, LME, stored_uas=stored_uas)\n",
    "    stored_uas = None"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
