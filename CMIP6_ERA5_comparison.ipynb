{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tk/.local/lib/python3.9/site-packages/gribapi/__init__.py:23: UserWarning: ecCodes 2.31.0 or higher is recommended. You are running version 2.24.2\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import netCDF4\n",
    "import xarray as xr\n",
    "import matplotlib as mpl\n",
    "import cdsapi\n",
    "import numpy as np\n",
    "import warnings\n",
    "import regionmask\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('default')\n",
    "import cftime\n",
    "import os\n",
    "import seaborn as sns\n",
    "import cartopy\n",
    "import cartopy.feature as cpf\n",
    "from global_land_mask import globe\n",
    "import CMIP6_light_map\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from shapely.geometry import box, mapping\n",
    "import geopandas as gpd\n",
    "import rioxarray\n",
    "from matplotlib import cm\n",
    "import cartopy.feature as cpf\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def convert_to_180(ds):\n",
    "    return ds.assign_coords(lon=(((ds.lon + 180) % 360) - 180)).sortby('lon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_era5(era_datafile, start_time, end_time):\n",
    "    era = netCDF4.Dataset(era_datafile)\n",
    "    units = 'hours since 1900-01-01 00:00:00.0'\n",
    "    time_gregorian = cftime.num2date(era.variables[\"time\"], units, 'gregorian')\n",
    "    units_to_wm2 =1./3600.\n",
    "\n",
    "    times=[]\n",
    "    for t in time_gregorian:\n",
    "        obj = datetime.datetime(year=t.year, month=t.month, day=t.month, hour=t.hour)\n",
    "        times.append(obj)\n",
    "    times = pd.to_datetime(times,dayfirst=False)\n",
    "\n",
    "    era = xr.open_dataset(era_datafile,\n",
    "                          mask_and_scale=True)*units_to_wm2\n",
    "\n",
    "    era = era.assign_coords({\"time\":times,\"latitude\":era.latitude,\"longitude\":era.longitude})\n",
    "    return era.rename({\"latitude\":\"lat\", \"longitude\":\"lon\"}).sel(time=slice(start_time,end_time))\n",
    "\n",
    "def get_mean_era5(era_datafile, start_time, end_time):\n",
    "    era = netCDF4.Dataset(era_datafile)\n",
    "\n",
    "    units = 'hours since 1900-01-01 00:00:00.0'\n",
    "    time_gregorian = cftime.num2date(era.variables[\"time\"], units, 'gregorian')\n",
    "    units_to_wm2 =1.\n",
    "\n",
    "    times=[]\n",
    "    for t in time_gregorian:\n",
    "        obj = datetime.datetime(year=t.year, month=t.month, day=t.month, hour=t.hour)\n",
    "        times.append(obj)\n",
    "    times = pd.to_datetime(times,dayfirst=False)\n",
    "\n",
    "    era = xr.open_dataset(era_datafile,\n",
    "                          mask_and_scale=True)*units_to_wm2\n",
    "\n",
    "    era = era.assign_coords({\"time\":times,\"latitude\":era.latitude,\"longitude\":era.longitude})\n",
    "    return era.rename({\"latitude\":\"lat\", \"longitude\":\"lon\"}).sel(time=slice(start_time,end_time))\n",
    "\n",
    "def get_area_averaged_ds(fname,scenario,model,min_lat,max_lat,min_lon,max_lon,var_name,LME):\n",
    "\n",
    "    with xr.open_dataset(fname) as ds:\n",
    "\n",
    "        ds=convert_to_180(ds)\n",
    "        ds=ds.sel(time=slice(start_time,end_time)).sel(lat=slice(min_lat,max_lat), lon=slice(min_lon,max_lon))\n",
    "        lon_c,lat_c=np.meshgrid(ds.lon.values,ds.lat.values)\n",
    "        is_in_ocean_c = globe.is_ocean(lat_c,lon_c)\n",
    "        ds.coords['mask'] = (('lat', 'lon'), is_in_ocean_c)\n",
    "\n",
    "        ds = ds[var_name].where(ds.mask==1).fillna(0)\n",
    "        ds = get_data_within_LME(ds, var_name, LME, create_map=False)\n",
    "\n",
    "        ds=ds.sel(time=slice(\"1979-01-01\",\"2021-01-01\")).mean({\"lat\",\"lon\"})\n",
    "        df = ds.to_dataframe().dropna()\n",
    "        df = df.reset_index()\n",
    "        df[\"scenario\"]=scenario\n",
    "        df[\"model\"]=model\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_LME_records():\n",
    "    lme_file='../oceanography/Shapefiles/LME66/LMEs66.shp'\n",
    "    return gpd.read_file(lme_file)\n",
    "\n",
    "def get_LME_records_plot():\n",
    "    lme_file='../oceanography/Shapefiles/LME66_180/LME66_180.shp'\n",
    "    return gpd.read_file(lme_file)\n",
    "\n",
    "def create_colors(N):\n",
    "    color=iter(cm.tab20b(np.linspace(0,1,N)))\n",
    "    return [next(color) for c in range(N)]\n",
    "\n",
    "def create_map(df, title, var_name, period, anomalies=False, details=False):\n",
    "    if details is True:\n",
    "        lonmin=-165\n",
    "        lonmax=-143.5\n",
    "        latmin=53.5\n",
    "        latmax=65.0\n",
    "        res=\"10m\"\n",
    "    else:\n",
    "        lonmin=-252\n",
    "        lonmax=-100.5\n",
    "        latmin=20\n",
    "        latmax=80\n",
    "        res=\"50m\"\n",
    "    ax = plt.figure(figsize=(16,10)).gca(projection=cartopy.crs.PlateCarree(central_longitude=-180))\n",
    "\n",
    "    ax.coastlines(resolution=res, linewidth=0.6, color=\"black\", alpha=0.8, zorder=4)\n",
    "    ax.add_feature(cpf.BORDERS, linestyle=':',alpha=0.4)\n",
    "    ax.add_feature(cpf.LAND, color=\"lightgrey\")\n",
    "    ax.set_extent([lonmin, lonmax, latmin, latmax])\n",
    "\n",
    "    xticks = np.linspace(lonmin, lonmax, 5)\n",
    "    yticks = np.linspace(latmin, latmax, 5)\n",
    "\n",
    "    ax.set_xticks(xticks, crs=cartopy.crs.PlateCarree())\n",
    "    ax.set_yticks(yticks, crs=cartopy.crs.PlateCarree())\n",
    "    lon_formatter = LongitudeFormatter(zero_direction_label=True)\n",
    "    lat_formatter = LatitudeFormatter()\n",
    "    ax.xaxis.set_major_formatter(lon_formatter)\n",
    "    ax.yaxis.set_major_formatter(lat_formatter)\n",
    "\n",
    "    #if var_name in [\"par\"]:\n",
    "    clb_label='PAR ($W/m^{2}$)'\n",
    "    cs=ax.contourf(df[\"lon\"], df[\"lat\"], df[var_name], #np.where(df[\"H\"] < 0, df[\"H\"], np.nan), # df[var_name],\n",
    "                   cmap=sns.color_palette(\"Spectral_r\", as_cmap=True),\n",
    "                   transform=ccrs.PlateCarree())\n",
    "    #else:\n",
    "    #    if anomalies is True:\n",
    "    #        pal=sns.color_palette(\"coolwarm\", as_cmap=True)\n",
    "    #    else:\n",
    "    #        pal=sns.color_palette(\"coolwarm\", as_cmap=True)\n",
    "\n",
    "    if title not in [\"Bathymetry\"]:\n",
    "        clb = plt.colorbar(cs, shrink=0.5, extend=\"both\")\n",
    "\n",
    "    plt.xlabel(\"Longitude\")\n",
    "    plt.ylabel(\"Latitude\")\n",
    "\n",
    "    #if details:\n",
    "    #    plt.savefig(\"../../GOA-Laurel/Figures/Bottom_{}_july_sept_250m_zoomed_{}.png\".format(var_name, period), dpi=300,\n",
    "    #                facecolor='w',\n",
    "    #                transparent=False,\n",
    "    #                bbox_inches = 'tight',\n",
    "    #                pad_inches = 0)\n",
    "    #else:\n",
    "    #    plt.savefig(\"../../GOA-Laurel/Figures/Bottom_{}_july_sept_250m_{}.png\".format(var_name, period), dpi=300,\n",
    "    #            facecolor='w',\n",
    "    #                transparent=False,\n",
    "    #                bbox_inches = 'tight',\n",
    "    #                pad_inches = 0)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def create_LME_figure(ax, LMES, projection, show, extent):\n",
    "\n",
    "  #  ax.add_feature(cfeature.LAND, color=\"darkgrey\",zorder=20)\n",
    " #   ax.add_feature(cfeature.BORDERS, linestyle=':',alpha=0.4, zorder=20)\n",
    "   # ax.add_feature(cfeature.COASTLINE, color=\"whitesmoke\", linewidth=0.5, zorder=21)\n",
    "    ax.set_extent(extent, ccrs.PlateCarree())\n",
    "\n",
    "    # Get the -180-180 projected shapefile containing LMEs to make it\n",
    "    # easy to plot across the Pacific Ocean\n",
    "    shdf = get_LME_records_plot()\n",
    "    colors_rgb=create_colors(len(LMES))\n",
    "    counter=0\n",
    "    for LME_NAME,LME_NUMBER in zip(shdf['LME_NAME'],shdf['LME_NUMBER']):\n",
    "\n",
    "        shdf_sel = shdf[ shdf['LME_NAME']==LME_NAME ]\n",
    "\n",
    "        if (LME_NAME in LMES):\n",
    "           # print(\"Adding geometry for LME {}\".format(LME_NAME))\n",
    "            # Add the geometry and fill it with color\n",
    "            if len(LMES)==1:\n",
    "                color=\"tab:red\"\n",
    "            else:\n",
    "                color=colors_rgb[counter]\n",
    "            ax.add_geometries(shdf_sel['geometry'],\n",
    "                              projection,\n",
    "                              facecolor=color,\n",
    "                              edgecolor='k',linewidth=0.3)\n",
    "\n",
    "            # Add the label LME_NUMBER of the selected LME at the center of the LME\n",
    "         #   ax.annotate(s=LME_NUMBER,\n",
    "         #               xy=(shdf_sel.centroid.x,shdf_sel.centroid.y),\n",
    "         #               color=\"white\",\n",
    "         #               fontsize=13)\n",
    "            counter+=1\n",
    "        else:\n",
    "            ax.add_geometries(shdf_sel['geometry'],\n",
    "                              projection,\n",
    "                              facecolor='whitesmoke',\n",
    "                              edgecolor='k',linewidth=0.3)\n",
    "\n",
    "    if show:\n",
    "        plotfile=\"Figures/CMIP6_lightpaper_map_{}.png\".format(LMES[0])\n",
    "        print(\"Created figure {}\".format(plotfile))\n",
    "        plt.savefig(plotfile, dpi=200,\n",
    "                        bbox_inches = 'tight')\n",
    "        plt.show()\n",
    "\n",
    "def get_data_within_LME(ds,var_name,LME, create_map):\n",
    "\n",
    "    # Extract the polygon defining the boundaries of the LME\n",
    "    shdf = get_LME_records()\n",
    "    #print(\"Working on LME: {}\".format(LME)) #,shdf['LME_NAME'])\n",
    "\n",
    "    shdf_sel = shdf[ shdf['LME_NAME']==LME ]\n",
    "\n",
    "    # Setup the figure panels\n",
    "    if create_map:\n",
    "        fig = plt.figure(figsize=(13, 8))\n",
    "        if LME in [\"Barents Sea\",\"Central Arctic\"]:\n",
    "            projection=ccrs.NorthPolarStereo() #ccrs.PlateCarree(central_longitude=0)\n",
    "            extent = [-20, 90, 60, 90]\n",
    "            extent = [-180, 180, 50, 90]\n",
    "        else:\n",
    "            #projection=ccrs.PlateCarree(central_longitude=-180)\n",
    "            projection=ccrs.NorthPolarStereo()\n",
    "\n",
    "            extent = [-252, -100, 10, 65]\n",
    "            extent = [-200, -105, 40, 80]\n",
    "            extent = [-180, 180, 50, 90]\n",
    "          #  extent = [0, 360, 60, 90]\n",
    "        ax1 = fig.add_subplot(111, projection=projection)\n",
    "\n",
    "        # Create the map of the LME boundaries and color it.\n",
    "        # The active LME has color while the others are grey.\n",
    "\n",
    "        create_LME_figure(ax1, [LME], ccrs.PlateCarree(central_longitude=-180),True,extent)\n",
    "\n",
    "    # We need to add the projection to the dataset. Lon and lat projections are WGS84 (epsg:4326)\n",
    "\n",
    "    ds.coords['lon'] = (ds.coords['lon'] + 180) % 360 - 180\n",
    "    ds = ds.sortby(ds.lon)\n",
    "\n",
    "    # Rioxarray requires x and y dimensions - we convert these back to lon and lat later.\n",
    "    # We also add the projection (lat-lon) so that rioxarray can do the clipping of the data according to the\n",
    "    # shapefile.\n",
    "\n",
    "    tos=ds.rename({'lon': 'x','lat': 'y'})\n",
    "    tos=tos.rio.write_crs(4326)\n",
    "\n",
    "    # Clip the data within the LME. We have to convert the polygon geometry to a geodataframe using\n",
    "    # `shapely.geometry`. The clipping of data within the polygon is done using rioxarray.clip function\n",
    "\n",
    "    clipped = tos.rio.clip(geometries=shdf_sel.geometry.apply(mapping), crs=tos.rio.crs)\n",
    "    clipped=clipped.rename({'x': 'lon','y': 'lat'}).to_dataset()\n",
    "\n",
    "    p1=\"2000-01-01 to 2020-01-01\"\n",
    "    p2=\"2080-01-01 to 2020-01-01\"\n",
    "\n",
    "    create_maps=False\n",
    "    if create_maps:\n",
    "        clipped_p1=clipped.sel(time=slice(\"2000-01-01\",\"2020-01-01\")).mean({\"time\"})\n",
    "        clipped_p2=clipped.sel(time=slice(\"2080-01-01\",\"2099-12-16\")).mean({\"time\"})\n",
    "\n",
    "        create_map(clipped_p1, \"{} 2000-01-01 to 2020-01-01\".format(var_name), var_name, period=p1, anomalies=False, details=False)\n",
    "        create_map(clipped_p2, \"{} 2080-01-01 to 2020-01-01\".format(var_name), var_name, period=p2, anomalies=False, details=False)\n",
    "\n",
    "        plt.show()\n",
    "    return clipped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "ERA5 data can be downloaded from Copernicus\n",
    "https://climate.copernicus.eu/climate-reanalysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 25th Percentile\n",
    "def q25(x):\n",
    "    return x.quantile(0.1)\n",
    "\n",
    "# 75th Percentile\n",
    "def q75(x):\n",
    "    return x.quantile(0.9)\n",
    "\n",
    "# Calculate stats on dataframe\n",
    "def calculate_stats(df, var_name):\n",
    "    # https://stackoverflow.com/questions/53519823/confidence-interval-in-python-dataframe\n",
    "    stats = df[var_name].groupby(df.time.dt.month).agg(['mean', 'count', 'std', q25, q75,])\n",
    "    ci95_hi = []\n",
    "    ci95_lo = []\n",
    "\n",
    "    for i in stats.index:\n",
    "        m, c, s, mi, ma = stats.loc[i]\n",
    "        ci95_hi.append(m + 1.95*s/np.sqrt(c))\n",
    "        ci95_lo.append(m - 1.95*s/np.sqrt(c))\n",
    "\n",
    "    stats['ci95_hi'] = ci95_hi\n",
    "    stats['ci95_lo'] = ci95_lo\n",
    "\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'msdwswrf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/home/sam/miniconda3/envs/actea-3.9/lib/python3.9/site-packages/xarray/core/dataset.py:1317\u001b[0m, in \u001b[0;36mDataset._construct_dataarray\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1316\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1317\u001b[0m     variable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variables\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   1318\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'msdwswrf'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:43\u001b[0m\n",
      "File \u001b[0;32m/home/sam/miniconda3/envs/actea-3.9/lib/python3.9/site-packages/xarray/core/dataset.py:1410\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39misel(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkey)\n\u001b[1;32m   1409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m utils\u001b[38;5;241m.\u001b[39mhashable(key):\n\u001b[0;32m-> 1410\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_construct_dataarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1411\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m utils\u001b[38;5;241m.\u001b[39miterable_of_hashable(key):\n\u001b[1;32m   1412\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_copy_listed(key)\n",
      "File \u001b[0;32m/home/sam/miniconda3/envs/actea-3.9/lib/python3.9/site-packages/xarray/core/dataset.py:1319\u001b[0m, in \u001b[0;36mDataset._construct_dataarray\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1317\u001b[0m     variable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variables[name]\n\u001b[1;32m   1318\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m-> 1319\u001b[0m     _, name, variable \u001b[38;5;241m=\u001b[39m \u001b[43m_get_virtual_variable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdims\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1321\u001b[0m needed_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(variable\u001b[38;5;241m.\u001b[39mdims)\n\u001b[1;32m   1323\u001b[0m coords: \u001b[38;5;28mdict\u001b[39m[Hashable, Variable] \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m/home/sam/miniconda3/envs/actea-3.9/lib/python3.9/site-packages/xarray/core/dataset.py:175\u001b[0m, in \u001b[0;36m_get_virtual_variable\u001b[0;34m(variables, key, dim_sizes)\u001b[0m\n\u001b[1;32m    173\u001b[0m split_key \u001b[38;5;241m=\u001b[39m key\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(split_key) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m--> 175\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m    177\u001b[0m ref_name, var_name \u001b[38;5;241m=\u001b[39m split_key\n\u001b[1;32m    178\u001b[0m ref_var \u001b[38;5;241m=\u001b[39m variables[ref_name]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'msdwswrf'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scenarios=[\"ssp585\",\"ssp245\"]\n",
    "member_range=1\n",
    "ensemble_ids = [\"r{}i{}p{}f{}\".format(str(i + 1), str(ii + 1), str(iii + 1), str(iv + 1)) for i in\n",
    "                           range(member_range)\n",
    "                           for ii in range(member_range) for iii in range(member_range) for iv in range(member_range)]\n",
    "\n",
    "period=\"1979-01-01-2099-12-16\"\n",
    "start_time=\"1979-01-01\"\n",
    "end_time=\"2099-12-16\"\n",
    "\n",
    "models=[\"ACCESS-ESM1-5\",\"CanESM5\",\"UKESM1-0-LL\",\"MPI-ESM1-2-LR\"]\n",
    "era_var_name1=\"msdwswrf\"\n",
    "era_var_name2=\"msdwuvrf\"\n",
    "ds_var_name1=\"ghi\"\n",
    "ds_var_name2=\"uv_srf\"\n",
    "\n",
    "ds_var_names=[\"ghi\",\"uv_srf\"] #[\"ghi\",\"osa\",\"par\",\"uvi\",\"uv\"]\n",
    "\n",
    "LMES=['California Current','East Bering Sea','Gulf of Alaska',\n",
    "              'Northern Bering - Chukchi Seas','West Bering Sea','Sea of Japan',\n",
    "              'Oyashio Current','Kuroshio Current','East China Sea',\n",
    "              'South China Sea','Sea of Okhotsk','Yellow Sea',\n",
    "              'Aleutian Islands']\n",
    "\n",
    "LMES=['Barents Sea','East Bering Sea','Central Arctic','Northern Bering - Chukchi Seas','Beaufort Sea'] #,'East Bering Sea','Beaufort Sea','Northern Bering - Chukchi Seas',\n",
    "\n",
    "era_datafile=\"/mnt/disks/actea-disk-1/light/era5/ERA5_global_hourly_shortwave.nc\"\n",
    "\n",
    "era = get_mean_era5(era_datafile, start_time, end_time)\n",
    "\n",
    "#distance = haversine(lon1,lat1,lon2,lat2)\n",
    "\n",
    "min_lat=60\n",
    "max_lat=85\n",
    "min_lon=-180\n",
    "max_lon=180\n",
    "era = era.reindex(lat=list(reversed(era.lat)))\n",
    "era = era.sel(lat=slice(min_lat,max_lat),lon=slice(min_lon,max_lon))\n",
    "\n",
    "lon1,lat1=np.meshgrid(era.lon.values,era.lat.values)\n",
    "is_in_ocean = globe.is_ocean(lat1,lon1)\n",
    "era.coords['mask'] = (('lat', 'lon'), is_in_ocean)\n",
    "era_ds1=era[era_var_name1]\n",
    "era_ds2=era[era_var_name2]\n",
    "\n",
    "for LME in LMES:\n",
    "\n",
    "    era5_lme1 = get_data_within_LME(era_ds1,era_var_name1,LME,create_map=False)\n",
    "    era5_lme2 = get_data_within_LME(era_ds2,era_var_name2,LME,create_map=False)\n",
    "\n",
    "    era1 = era5_lme1.mean({\"lat\",\"lon\"})\n",
    "    era2 = era5_lme2.mean({\"lat\",\"lon\"})\n",
    "\n",
    "    era_df1=era1.to_dataframe().reset_index()\n",
    "    era_df2=era2.to_dataframe().reset_index()\n",
    "\n",
    "    uv_dfs=[]\n",
    "    sw_dfs=[]\n",
    "\n",
    "    for scenario in scenarios:\n",
    "        for model in models:\n",
    "            for ensemble_id in ensemble_ids:\n",
    "                fname1 = \"../oceanography/light/ncfiles/{}_{}_{}_{}_scenario_osa_{}.nc\".format(ds_var_name1, model, ensemble_id,period,scenario)\n",
    "                fname2=\"../oceanography/light/ncfiles/{}_{}_{}_{}_scenario_osa_{}.nc\".format(ds_var_name2,model, ensemble_id,period,scenario)\n",
    "\n",
    "                if os.path.exists(fname1) and os.path.exists(fname2):\n",
    "\n",
    "                    df1 = get_area_averaged_ds(fname1,scenario,model,min_lat,max_lat,min_lon,max_lon,ds_var_name1,LME)\n",
    "                    df2 = get_area_averaged_ds(fname2,scenario,model,min_lat,max_lat,min_lon,max_lon,ds_var_name2,LME)\n",
    "\n",
    "                    sw_dfs.append(df1)\n",
    "                    uv_dfs.append(df2)\n",
    "\n",
    "    uv_df=pd.concat(uv_dfs)\n",
    "    sw_df=pd.concat(sw_dfs)\n",
    "\n",
    "    # Shortwave radiation as function of month (mean + 0.95 CI)\n",
    "    era_df_mean1 = calculate_stats(era_df1, era_var_name1)\n",
    "    sw_mean = calculate_stats(sw_df, ds_var_name1)\n",
    "\n",
    "    # UV (200-440nm) radiation as function of month (mean + 0.95 CI)\n",
    "    era_df_mean2 = calculate_stats(era_df2, era_var_name2)\n",
    "    uv_mean = calculate_stats(uv_df, ds_var_name2)\n",
    "\n",
    "    fig1=plt.figure(figsize=(10,5))\n",
    "    axes1 = fig1.add_subplot(121)\n",
    "    axes2 = fig1.add_subplot(122)\n",
    "\n",
    "    axes1.plot(era_df_mean1.index, era_df_mean1[\"mean\"], alpha=1.0, color=\"red\", label=\"ERA5 {}\".format(era_var_name1))\n",
    "    axes1.fill_between(era_df_mean1.index, era_df_mean1[\"ci95_lo\"], era_df_mean1[\"ci95_hi\"], alpha=0.1, color=\"red\")\n",
    "\n",
    "    axes1.plot(sw_mean.index, sw_mean[\"mean\"], alpha=1.0, color=\"orange\", label=\"GHI (200-2700 nm)\")\n",
    "    axes1.fill_between(sw_mean.index, sw_mean[\"q25\"], sw_mean[\"q75\"], alpha=0.1, color=\"orange\")\n",
    "    axes1.fill_between(sw_mean.index, sw_mean[\"ci95_lo\"], sw_mean[\"ci95_hi\"], alpha=0.3, color=\"orange\")\n",
    "    axes1.legend(loc=\"upper right\")\n",
    "\n",
    "    axes2.plot(era_df_mean2.index, era_df_mean2[\"mean\"], alpha=1.0, color=\"red\", label=\"UV (200-440 nm)\")\n",
    "    axes2.fill_between(era_df_mean2.index, era_df_mean2[\"q25\"], era_df_mean2[\"q75\"], alpha=0.1, color=\"red\")\n",
    "    axes2.fill_between(era_df_mean2.index, era_df_mean2[\"ci95_lo\"], era_df_mean2[\"ci95_hi\"], alpha=0.3, color=\"red\")\n",
    "\n",
    "    axes2.plot(uv_mean.index, uv_mean[\"mean\"], alpha=1.0, color=\"blue\", label=\"ERA5 {}\".format(era_var_name2))\n",
    "    axes2.fill_between(uv_mean.index, uv_mean[\"q25\"], uv_mean[\"q75\"], alpha=0.1, color=\"blue\")\n",
    "    axes2.fill_between(uv_mean.index, uv_mean[\"ci95_lo\"], uv_mean[\"ci95_hi\"], alpha=0.3, color=\"blue\")\n",
    "\n",
    "    axes1.set_ylabel(\"Downward shortwave radiation (Wm$^{-2}$)\")\n",
    "    axes2.set_ylabel(\"Downward UV radiation (Wm$^{-2}$)\")\n",
    "    axes1.set_xlabel(\"Month\")\n",
    "    axes2.set_xlabel(\"Month\")\n",
    "    axes2.legend(loc=\"upper right\")\n",
    "\n",
    "    merged = pd.merge_asof(era_df_mean1[\"mean\"], sw_mean[\"mean\"], left_index=True, right_index=True, direction='nearest')\n",
    "    print(merged)\n",
    "    merged_uv = pd.merge_asof(era_df_mean2[\"mean\"], uv_mean[\"mean\"], left_index=True, right_index=True, direction='nearest')\n",
    "    print(merged_uv)\n",
    "\n",
    "    print(\"Correlation PAR: {}\".format(merged.corr()))\n",
    "    print(\"Correlation UV: {}\".format(merged_uv.corr()))\n",
    "\n",
    "    plotfile=\"Figures/CMIP6_lightpaper_sw+uv_compared_ERA_{}.png\".format(LME)\n",
    "    print(\"Created figure {}\".format(plotfile))\n",
    "    plt.savefig(plotfile, dpi=300,\n",
    "                    bbox_inches = 'tight')\n",
    "    plt.show()\n",
    "\n",
    "    # For each variable in the list create a time-series plot\n",
    "    timeseries=False\n",
    "    if timeseries:\n",
    "        for var_name in ds_var_names:\n",
    "            for model in models:\n",
    "                for ensemble_id in ensemble_ids:\n",
    "                    fname = \"../oceanography/light/ncfiles/{}_{}_{}_{}_scenario_osa_{}.nc\".format(ds_var_name1, model,\n",
    "                                                                                                  ensemble_id,period,\n",
    "                                                                                                  scenario)\n",
    "\n",
    "                    if os.path.exists(fname):\n",
    "                        df = get_area_averaged_ds(fname,scenario,model,min_lat,max_lat,min_lon,max_lon,var_name,LME)\n",
    "                      #  df = uv_df\n",
    "                        df_a = df.resample(\"A\", on=\"time\").mean()\n",
    "                        fig2, axes2 = plt.subplots(1, 1)\n",
    "                        sns.lineplot(ax=axes2, data=df, x=df.time, y=var_name,\n",
    "                                     ci=95, alpha=0.65,\n",
    "                                     legend=\"auto\", label=\"CMIP6 {} monthly\".format(var_name))\n",
    "                        sns.lineplot(ax=axes2, data=df_a, x=df_a.index, y=var_name,\n",
    "                                     ci=95, alpha=0.95,\n",
    "                                     legend=\"auto\", label=\"CMIP6 {} annual\".format(var_name))\n",
    "\n",
    "                        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
